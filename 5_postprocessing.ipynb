{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee639da7-3595-482a-ae1b-d3d5d9d970c3",
   "metadata": {},
   "source": [
    "# Postprocesamiento y Limpieza de Datos\n",
    "Este código realiza el postprocesamiento y limpieza de datos extraídos de Resoluciones de Calificación Ambiental (RCA). Su propósito principal es:\n",
    "- Importación y preparación de datos\n",
    "- Eliminación de datos irrelevantes\n",
    "- Eliminación de duplicados\n",
    "- Clasificación y corrección\n",
    "- Exportación de datos limpios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fe460a-2581-42d3-955c-6fc33b0692de",
   "metadata": {},
   "source": [
    "## Importar y definir directorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "202781c2-bab6-41a8-afd4-5ac52178c6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Librerías estándar de Python\n",
    "import ast\n",
    "import copy\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import time\n",
    "import uuid\n",
    "import xml.etree.ElementTree as ET\n",
    "from enum import Enum\n",
    "from html import unescape\n",
    "from itertools import combinations, permutations, zip_longest\n",
    "from time import sleep\n",
    "\n",
    "# Manejo de documentos y archivos\n",
    "import docx\n",
    "import openpyxl\n",
    "import pdfplumber\n",
    "from PyPDF2 import PdfReader\n",
    "import tabula\n",
    "from tabula.io import read_pdf\n",
    "\n",
    "# Web scraping y requests\n",
    "import requests\n",
    "from bs4 import BeautifulSoupimport matplotlib.pyplot as plt\n",
    "# Minimal test for yfiles_jupyter_graphs\n",
    "import networkx as nx\n",
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.offline import plot\n",
    "import colorsys\n",
    "        from yfiles_jupyter_graphs import GraphWidget\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict\n",
    "from random import random\n",
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager\n",
    "from adjustText import adjust_text\n",
    "\n",
    "    # Crear leyenda para los ministerios con tamaño más grande\n",
    "    from matplotlib.lines import Line2D\n",
    "\n",
    "from networkx import florentine_families_graph\n",
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "from typing import Dict\n",
    "from yfiles_jupyter_graphs import GraphWidget\n",
    "from IPython.display import display\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "# Machine Learning / IA / Embeddings\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# APIs y entornos\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from openai import OpenAI, AzureOpenAI\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "import tiktoken\n",
    "\n",
    "# Pydantic y validación\n",
    "from pydantic import BaseModel, Field, ValidationError, model_validator, constr, conlist\n",
    "from typing import List, Optional, Literal, Annotated\n",
    "\n",
    "# Manejo de datos\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Fuzzy Matching\n",
    "from fuzzywuzzy import fuzz\n",
    "from thefuzz import fuzz, process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33770f5c-5378-4301-9665-9ee60b637a6a",
   "metadata": {},
   "source": [
    "### Establecer Directorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e36ff7-f8fa-4b3d-928c-dd8e00cc4bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sector = f\"energia\"\n",
    "path = os.path.join(os.environ['USERPROFILE'], \"RUTA\", f\"archivos_{sector}\")\n",
    "load_dotenv()\n",
    "api_key_openai = os.getenv(\"OPENAI_API_KEY\")\n",
    "client = openai.OpenAI(\n",
    "    api_key=api_key_openai\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1fa462-a34b-4dc2-823a-8d9b82c6b5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(os.path.join(path, \"obligaciones/obligaciones.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1bf33a-d306-48cc-af84-8a4493a7fb68",
   "metadata": {},
   "source": [
    "## Eliminar Errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e46407-df5d-4858-9f5e-05e8d28aa081",
   "metadata": {},
   "outputs": [],
   "source": [
    "condicion_eliminar = (df['justificacion'].str.strip().str.len() <= 15) & (df['resumen'].str.strip().str.len() <= 15)\n",
    "df_cleaned = df[~condicion_eliminar]\n",
    "print(f\"se eliminó un {(len(df) - len(df_cleaned))*100/len(df)} % de los datos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00665965-b4b4-48bb-b357-01596eb3f14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de términos prohibidos\n",
    "forbidden_terms = [\n",
    "    \"no identificado\", \"no aplica\", \"no se comprometen límites\",\n",
    "    \"No se especifica\", \"No se especifica en el texto\",\n",
    "    \"no identificado y nan\", \"no indicado\", \"no especificado\"\n",
    "]\n",
    "\n",
    "# Función para verificar similitud difusa\n",
    "def is_similar(value, terms, threshold=95):\n",
    "    if pd.isna(value):\n",
    "        return True\n",
    "    value_str = str(value).strip().lower()\n",
    "    if len(value_str) > 50:\n",
    "        return False\n",
    "    if len(value_str) <= 10:\n",
    "        return True\n",
    "    return any(fuzz.ratio(value_str, term.lower()) >= threshold for term in terms)\n",
    "\n",
    "df_cleaned = df_cleaned[df_cleaned['seccion'].isin(['pas', 'contingencias_emergencias']) |\n",
    "~(df_cleaned['resumen'].apply(lambda x: is_similar(x, forbidden_terms)) | \n",
    "  df_cleaned['justificacion'].apply(lambda x: is_similar(x, forbidden_terms)))]\n",
    "\n",
    "print(f\"se eliminó un {(len(df) - len(df_cleaned))*100/len(df)} % de los datos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ebdd877-c7d2-49b5-b742-102553e2790c",
   "metadata": {},
   "source": [
    "## Duplicados Exactos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39aab8b-e29d-480d-8336-6d797737abe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_original_df = len(df_cleaned)\n",
    "df_cleaned['numero_tabla'] = df_cleaned['numero_tabla'].astype(str) \n",
    "df_cleaned['numero_tabla_grupo'] = df_cleaned['numero_tabla'].str[:15]\n",
    "\n",
    "cond_just_valid = (df_cleaned['justificacion'] != \"\") & (df_cleaned['justificacion'].notna())\n",
    "df_cleaned = pd.concat([\n",
    "    df_cleaned[cond_just_valid].drop_duplicates(\n",
    "        subset=['cell', 'seccion', 'numero_tabla_grupo', 'justificacion'],\n",
    "        keep='first'\n",
    "    ),\n",
    "    df_cleaned[~cond_just_valid]\n",
    "], ignore_index=True)\n",
    "\n",
    "\n",
    "cond_res_valid = (df_cleaned['resumen'] != \"\") & (df_cleaned['resumen'].notna())\n",
    "df_cleaned = pd.concat([\n",
    "    df_cleaned[cond_res_valid].drop_duplicates(\n",
    "        subset=['cell', 'seccion', 'numero_tabla_grupo', 'resumen'],\n",
    "        keep='first'\n",
    "    ),\n",
    "    df_cleaned[~cond_res_valid]\n",
    "], ignore_index=True)\n",
    "\n",
    "\n",
    "indices_a_eliminar = set()\n",
    "for (seccion_val, cell_val), grupo in df_cleaned.groupby(['seccion', 'cell']):\n",
    "    no_identificados = grupo[grupo['numero_tabla_grupo'] == 'no identificado']\n",
    "    identificados = grupo[grupo['numero_tabla_grupo'] != 'no identificado']\n",
    "\n",
    "    if not no_identificados.empty and not identificados.empty:\n",
    "        justificaciones_identificadas = set(identificados['justificacion'].dropna())\n",
    "        resumenes_identificados = set(identificados['resumen'].dropna())\n",
    "\n",
    "        for idx, fila_ni in no_identificados.iterrows():\n",
    "            if (fila_ni['justificacion'] in justificaciones_identificadas or fila_ni['resumen'] in resumenes_identificados):\n",
    "                indices_a_eliminar.add(idx)\n",
    "\n",
    "# Eliminar las filas marcadas de df_cleaned\n",
    "if indices_a_eliminar:\n",
    "    df_cleaned = df_cleaned.drop(index=list(indices_a_eliminar))\n",
    "\n",
    "# Cálculo de Porcentaje Eliminado (Final)\n",
    "porcentaje_eliminado_total = (len_original_df - len(df_cleaned)) * 100 / len_original_df if len_original_df > 0 else 0\n",
    "print(f\"\\n### Proceso de Limpieza Completado ###\")\n",
    "print(f\"Porcentaje TOTAL de datos eliminados: {porcentaje_eliminado_total:.2f} %\")\n",
    "print(f\"Tamaño original del DataFrame: {len_original_df} filas\")\n",
    "print(f\"Tamaño final del DataFrame: {len(df_cleaned)} filas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967af73d-eddb-4832-bcf4-aa478e31ca9d",
   "metadata": {},
   "source": [
    "## Separar según Decretos PAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0585e025-50ee-4833-b6a0-0f0df65a8694",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_articulos_dict(texto):\n",
    "\n",
    "    regex = r\"Artículo (\\d+)\\.-\"\n",
    "    articulos = re.split(regex, texto)\n",
    "\n",
    "    # Asegurarse de que el primer elemento no cause problemas\n",
    "    if articulos and articulos[0]:\n",
    "        articulos = articulos[1:]\n",
    "    elif articulos:\n",
    "        articulos = articulos[1:]\n",
    "\n",
    "    articulos_dict = {}\n",
    "    for i in range(0, len(articulos) - 1, 2):\n",
    "        numero_articulo = articulos[i]\n",
    "        contenido = articulos[i + 1].strip()\n",
    "        articulos_dict[numero_articulo] = contenido\n",
    "\n",
    "    return articulos_dict\n",
    "\n",
    "def agregar_contenido_articulo(df, articulos_dict):\n",
    "\n",
    "    df['contenido_articulo'] = df.apply(\n",
    "        lambda row: articulos_dict.get(row['numero_fuente'].strip(\"['']\"), pd.NA)\n",
    "        if row['seccion'] == 'pas'\n",
    "        else pd.NA,\n",
    "        axis=1,\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Ruta al archivo Word\n",
    "word_file_path = os.path.join(os.environ['USERPROFILE'], \"RUTA\", \"PAS.docx\")\n",
    "\n",
    "# Leer el contenido del archivo Word\n",
    "doc = docx.Document(word_file_path)\n",
    "full_text = []\n",
    "for paragraph in doc.paragraphs:\n",
    "    full_text.append(paragraph.text)\n",
    "texto = '\\n'.join(full_text)\n",
    "\n",
    "# Procesar el texto para extraer los artículos en un diccionario\n",
    "articulos_dict = extract_articulos_dict(texto)\n",
    "\n",
    "# Agregar la columna 'contenido_articulo'\n",
    "df_cleaned = agregar_contenido_articulo(df_cleaned, articulos_dict)  \n",
    "\n",
    "def get_embedding(text, deployment_name):\n",
    "    \"\"\"Obtiene el embedding para un texto dado.\"\"\"\n",
    "    response = client.embeddings.create(input=[text], model=deployment_name)\n",
    "    return np.array(response.data[0].embedding)\n",
    "\n",
    "def cosine_similarity(emb1, emb2):\n",
    "    \"\"\"Calcula la similitud coseno entre dos embeddings.\"\"\"\n",
    "    return dot(emb1, emb2) / (norm(emb1) * norm(emb2)) if (norm(emb1) * norm(emb2)) != 0 else 0\n",
    "\n",
    "lista_de_terminos = df_cleaned.sin_condiciones.value_counts(normalize=True).head(n=30).index.tolist()\n",
    "\n",
    "\n",
    "def limpiar_condiciones_avanzado(texto_original):\n",
    "    if pd.isna(texto_original):\n",
    "        return None \n",
    "\n",
    "    texto = str(texto_original)\n",
    "    texto = texto.replace(u'\\xa0', ' ')  \n",
    "    texto = texto.replace('\\n', ' ')    \n",
    "    texto = texto.lstrip('- ')          \n",
    "    texto = re.sub(r'\\s+', ' ', texto).strip() \n",
    "    texto_lower = texto.lower()\n",
    "    s_c_normalizado = \"S/C\" \n",
    "\n",
    "    terminos_exactos_para_sc = {\n",
    "        \"s/c\": s_c_normalizado,\n",
    "        \"s/c.\": s_c_normalizado,\n",
    "        \"s/c,\": s_c_normalizado,\n",
    "        \"s / c\": s_c_normalizado,\n",
    "        \"s / c.\": s_c_normalizado,\n",
    "        \"s / c,\": s_c_normalizado,\n",
    "        \"no identificado\": s_c_normalizado,\n",
    "        \"no hay.\": s_c_normalizado,\n",
    "        \"no hay\": s_c_normalizado,\n",
    "        \"ninguna\": s_c_normalizado,\n",
    "        \"ninguna.\": s_c_normalizado,\n",
    "        \"no\": s_c_normalizado, \n",
    "        \"s/c, s/c\": s_c_normalizado,\n",
    "        \"s/c, s/c, s/c\": s_c_normalizado,\n",
    "    }\n",
    "    if texto_lower in terminos_exactos_para_sc:\n",
    "        return terminos_exactos_para_sc[texto_lower]\n",
    "\n",
    "    patrones_frases_sc_completas = [\n",
    "        r\"no se especifican acciones de emergencia en el texto proporcionado\\.?\",\n",
    "        r\"no se especifican acciones de emergencia en el texto\\.?\",\n",
    "        r\"las emisiones producidas por el proyecto se encuentran debidamente abordadas por las medidas de control propuestas por el titular del proyecto y no generarán riesgo a la salud de la población del área de influencia del proyecto debido a la cantidad y calidad de efluentes, emisiones o residuos\\.?\",\n",
    "        r\"las emisiones producidas por el proyecto se encuentran debidamente abordadas por las medidas de control propuestas por el titular del proyecto y no generarán riesgo a la salud de la población del área de influencia del proyecto debido a la cantidad y calidad de efluentes, emisiones o residuos, tal como se puede apreciar en el punto \\d+\\.\\d+\\.\\d+ del ice\\.?\",\n",
    "        r\"el requisito para su otorgamiento consiste en que las condiciones de saneamiento y seguridad eviten un riesgo a la salud de la población\\.?\",\n",
    "        r\"la seremi de salud, órgano del estado que otorga dicho permiso, se pronuncia conforme a los antecedentes presentados, mediante oficio ord\\. no \\d+ de fecha \\d{1,2} de \\w+ de \\d{4}\\.?\",\n",
    "        r\"no existen condiciones o exigencias asociadas a este permiso\\. pronunciamiento del órgano competente: mediante ord\\. n°\\d+ de fecha \\d{1,2}/\\d{1,2}/\\d{4}, la seremi de salud, región de [\\w\\s]+, se pronunció conforme\\.?\",\n",
    "        r\"sin condiciones\\.?\",\n",
    "        r\"no se establecen condiciones\\.?\",\n",
    "        r\"no se establecieron condiciones\\.?\",\n",
    "        r\"no existen condiciones\\.?\",\n",
    "        r\"sin restricciones\\.?\",\n",
    "        r\"no hay condiciones\\.?\",\n",
    "        r\"no aplican condiciones\\.?\",\n",
    "        r\"ninguna condición\\.?\"\n",
    "    ]\n",
    "    for patron in patrones_frases_sc_completas:\n",
    "        if re.fullmatch(patron, texto_lower):\n",
    "            return s_c_normalizado\n",
    "\n",
    "    match_sc_al_inicio = re.match(r\"^(s\\s*/\\s*c\\b'*[\\.,]?)\\s*\", texto_lower)\n",
    "\n",
    "    if match_sc_al_inicio:\n",
    "        longitud_prefijo_sc = len(match_sc_al_inicio.group(0))\n",
    "        contenido_despues_sc = texto[longitud_prefijo_sc:].strip()\n",
    "\n",
    "        patrones_ruido_despues_de_sc = [\n",
    "            r\"^,'frecuencia':'eventual'[\\.,]?\\s*\",\n",
    "            r\"^\\['\\\"\\]?,\\s*\\['\\\"\\]?frecuencia\\['\\\"\\]?\\s*:\\s*\\['\\\"\\]?eventual\\['\\\"\\]?\\.?,?\\s*\",\n",
    "            r\"^\\(?(no\\s+hay)\\)?\\.?,?\\s*\",\n",
    "            r\"^frecuencia\\s*:\\s*eventual\\.?,?\\s*\",\n",
    "            r\"^frecuencia\\s*eventual\\.?,?\\s*\",\n",
    "            r\"^frecuencia\\.?,?\\s*\",\n",
    "        ]\n",
    "        \n",
    "        contenido_provisional = contenido_despues_sc\n",
    "        for patron_ruido in patrones_ruido_despues_de_sc:\n",
    "            contenido_provisional = re.sub(patron_ruido, \"\", contenido_provisional, count=1, flags=re.IGNORECASE).strip()\n",
    "        \n",
    "        contenido_final_despues_sc = contenido_provisional.lstrip(',. ').strip()\n",
    "\n",
    "        if not contenido_final_despues_sc:\n",
    "            return s_c_normalizado\n",
    "        else:\n",
    "            if contenido_final_despues_sc.lower() in [\"s/c\", \"s/c.\", \"s/c,\"]:\n",
    "                return s_c_normalizado\n",
    "            return f\"{s_c_normalizado}, {contenido_final_despues_sc}\"\n",
    "\n",
    "    patrones_genericos_sc_embebidos = [\n",
    "        r\"sin condiciones\", r\"no se establecen condiciones\", r\"no se establecieron condiciones\",\n",
    "        r\"no existen condiciones\", r\"sin restricciones\", r\"no hay condiciones\",\n",
    "        r\"no aplican condiciones\", r\"ninguna condición\"\n",
    "    ]\n",
    "    for patron in patrones_genericos_sc_embebidos:\n",
    "        if re.search(patron, texto_lower):\n",
    "            if len(texto_lower) < 50 and not re.search(r\"(pero|excepto|salvo|aunque|no obstante|sin embargo)\", texto_lower):\n",
    "                return s_c_normalizado\n",
    "            break \n",
    "    return texto\n",
    "\n",
    "df_cleaned['sin_condiciones'] = df_cleaned['sin_condiciones'].apply(limpiar_condiciones_avanzado)\n",
    "df_cleaned['similitud_fuzz'] = None\n",
    "df_cleaned['similitud_embedding'] = None\n",
    "df_cleaned['sin_condiciones_final'] = None \n",
    "\n",
    "for index, row in df_cleaned.iterrows():\n",
    "    if isinstance(row['sin_condiciones'], str) and isinstance(row['contenido_articulo'], str):\n",
    "        print(row['cell'])\n",
    "        fuzz_similarity = fuzz.partial_ratio(row['sin_condiciones'], row['contenido_articulo']) / 100.0 \n",
    "        df_cleaned.loc[index, 'similitud_fuzz'] = fuzz_similarity\n",
    "        try:\n",
    "            embedding_sin_condiciones = get_embedding(row['sin_condiciones'], \"text-embedding-3-large\")\n",
    "            embedding_contenido_articulo = get_embedding(row['contenido_articulo'], \"text-embedding-3-large\")\n",
    "            if embedding_sin_condiciones is not None and embedding_contenido_articulo is not None:\n",
    "                similarity = cosine_similarity(embedding_contenido_articulo, embedding_sin_condiciones)\n",
    "                df_cleaned.loc[index, 'similitud_embedding'] = similarity\n",
    "                print(fuzz_similarity, similarity)\n",
    "                if similarity > 0.60 or fuzz_similarity > 0.60:\n",
    "                    df_cleaned.loc[index, 'sin_condiciones_final'] = 'Se se establecen condiciones adicionales distintas a las del artículo'\n",
    "                else:\n",
    "                    df_cleaned.loc[index, 'sin_condiciones_final'] = 'No se establecen condiciones adicionales distintas a las del artículo' \n",
    "            else:\n",
    "                df_cleaned.loc[index, 'similitud_embedding'] = None\n",
    "                df_cleaned.loc[index, 'sin_condiciones_final'] = 'No se establecen condiciones'\n",
    "        except Exception as e:\n",
    "            print(f\"Error calculating embedding similarity for row {index}: {e}\")\n",
    "            df_cleaned.loc[index, 'similitud_embedding'] = None\n",
    "            df_cleaned.loc[index, 'sin_condiciones_final'] = 'No se establecen condiciones'\n",
    "    else:\n",
    "        df_cleaned.loc[index, 'sin_condiciones_final'] = 'No se establecen condiciones' \n",
    "\n",
    "print(df_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1856e9-4e40-46b0-abed-86cb7cd3c10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.to_excel(os.path.join(path, \"df_obligaciones_pre_filtradas_2.xlsx\"), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54509db-ee76-4cde-92fc-78eabe9eb614",
   "metadata": {},
   "source": [
    "## Eliminar Duplicados Semánticos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059e8ab9-29ed-4d2b-9360-25d03a650698",
   "metadata": {},
   "source": [
    "### Detección Semántica de Duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38441322-de1d-4f03-b243-b2d44f6ecf13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_X = pd.read_excel(os.path.join(path, \"df_obligaciones_pre_filtradas_2.xlsx\"))\n",
    "\n",
    "# Variables globales para seguimiento de costos y tokens de embeddings\n",
    "embedding_costs = {\"text-embedding-3-large\": 0.00013}\n",
    "total_embedding_tokens = 0\n",
    "total_embedding_cost = 0.0\n",
    "embedding_calls = 0\n",
    "\n",
    "# Función para contar tokens para OpenAI\n",
    "def count_tokens_embeddings(text, model=\"text-embedding-3-large\"):\n",
    "    \"\"\"Cuenta los tokens para el modelo de embeddings especificado.\"\"\"\n",
    "    # Encoding correcto según el modelo\n",
    "    if \"text-embedding-3\" in model:\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    else: \n",
    "        encoding = tiktoken.get_encoding(\"p50k_base\")\n",
    "    \n",
    "    token_list = encoding.encode(text)\n",
    "    return len(token_list)\n",
    "\n",
    "\n",
    "# Método 2: Usando directamente la biblioteca de OpenAI\n",
    "def similitud_embeddings_direct(texto1, texto2, api_key, endpoint, deployment_name, api_version=\"2024-02-01\", track_usage=True):\n",
    "    global total_embedding_tokens, total_embedding_cost, embedding_calls\n",
    "    \n",
    "    if not isinstance(texto1, str) or not isinstance(texto2, str):\n",
    "        return 0, None\n",
    "    \n",
    "    model = \"text-embedding-3-large\"\n",
    "    \n",
    "    # Contar tokens antes de enviar a la API\n",
    "    tokens_texto1 = count_tokens_embeddings(texto1, model) if track_usage else 0\n",
    "    tokens_texto2 = count_tokens_embeddings(texto2, model) if track_usage else 0\n",
    "    total_tokens = tokens_texto1 + tokens_texto2\n",
    "    \n",
    "    # Calcular costo\n",
    "    if track_usage:\n",
    "        cost_rate = embedding_costs.get(model, 0.0001)  \n",
    "        cost = (total_tokens / 1000) * cost_rate\n",
    "        \n",
    "        # Actualizar contadores globales\n",
    "        total_embedding_tokens += total_tokens\n",
    "        total_embedding_cost += cost\n",
    "        embedding_calls += 1\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        # Obtener embeddings para ambos textos\n",
    "        response1 = client.embeddings.create(\n",
    "            input=texto1,\n",
    "            model=deployment_name\n",
    "        )\n",
    "        def get_embedding(text, deployment_name):\n",
    "            \"\"\"Obtiene el embedding para un texto dado.\"\"\"\n",
    "            response = client.embeddings.create(input=[text], model=deployment_name)\n",
    "            return np.array(response.data[0].embedding)\n",
    "\n",
    "        \n",
    "        response2 = client.embeddings.create(\n",
    "            input=texto2,\n",
    "            model=deployment_name\n",
    "        )\n",
    "        \n",
    "        # Extraer los vectores de embedding\n",
    "        embedding1 = np.array(response1.data[0].embedding)\n",
    "        embedding2 = np.array(response2.data[0].embedding)\n",
    "        \n",
    "        # Calcular similitud coseno\n",
    "        cos_sim = dot(embedding1, embedding2) / (norm(embedding1) * norm(embedding2))\n",
    "        cos_sim = max(min(cos_sim, 1.0), 0.0)\n",
    "        \n",
    "        # Obtener tokens reales de la respuesta (si está disponible)\n",
    "        if hasattr(response1, 'usage') and hasattr(response1.usage, 'total_tokens'):\n",
    "            tokens_real1 = response1.usage.total_tokens\n",
    "        else:\n",
    "            tokens_real1 = tokens_texto1\n",
    "            \n",
    "        if hasattr(response2, 'usage') and hasattr(response2.usage, 'total_tokens'):\n",
    "            tokens_real2 = response2.usage.total_tokens\n",
    "        else:\n",
    "            tokens_real2 = tokens_texto2\n",
    "            \n",
    "        total_tokens_real = tokens_real1 + tokens_real2\n",
    "        \n",
    "        # Actualizar costo con tokens reales\n",
    "        if track_usage and total_tokens != total_tokens_real:\n",
    "            # Ajustar contadores globales si hay diferencia\n",
    "            total_embedding_tokens = total_embedding_tokens - total_tokens + total_tokens_real\n",
    "            cost_real = (total_tokens_real / 1000) * cost_rate\n",
    "            total_embedding_cost = total_embedding_cost - cost + cost_real\n",
    "            cost = cost_real\n",
    "        \n",
    "        # Crear información de uso\n",
    "        if track_usage:\n",
    "            usage_info = {\n",
    "                'modelo': model,\n",
    "                'deployment': deployment_name,\n",
    "                'tokens_texto1': tokens_real1,\n",
    "                'tokens_texto2': tokens_real2,\n",
    "                'total_tokens': total_tokens_real,\n",
    "                'costo': f\"{cost:.6f} USD\",\n",
    "                'total_acumulado': {\n",
    "                    'llamadas': embedding_calls,\n",
    "                    'tokens': total_embedding_tokens,\n",
    "                    'costo': f\"{total_embedding_cost:.6f} USD\"\n",
    "                }\n",
    "            }\n",
    "        else:\n",
    "            usage_info = None\n",
    "        \n",
    "        return cos_sim * 100, usage_info\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error al calcular embeddings directamente: {e}\")\n",
    "        if track_usage:\n",
    "            usage_info = {\n",
    "                'modelo': model,\n",
    "                'deployment': deployment_name,\n",
    "                'tokens_texto1': tokens_texto1,\n",
    "                'tokens_texto2': tokens_texto2,\n",
    "                'total_tokens': total_tokens,\n",
    "                'costo': f\"{cost:.6f} USD\",\n",
    "                'error': str(e),\n",
    "                'total_acumulado': {\n",
    "                    'llamadas': embedding_calls,\n",
    "                    'tokens': total_embedding_tokens,\n",
    "                    'costo': f\"{total_embedding_cost:.6f} USD\"\n",
    "                }\n",
    "            }\n",
    "            return 0, usage_info\n",
    "        return 0, None\n",
    "\n",
    "def similitud_embeddings(texto1, texto2, api_key, endpoint, deployment_name, api_version=\"2024-02-01\", use_langchain=False, track_usage=True):\n",
    "    if use_langchain:\n",
    "        return \"ERROR\"\n",
    "    else:\n",
    "        return similitud_embeddings_direct(texto1, texto2, api_key, endpoint, deployment_name, api_version, track_usage)\n",
    "\n",
    "# Código modificado para procesar el DataFrame completo\n",
    "def procesar_similitudes(df_filtered, api_key, endpoint, deployment_name, api_version=\"2024-02-01\", \n",
    "                         umbral_similitud=85, use_langchain=False, path=\".\", output_filename=\"obligaciones_filtradas.xlsx\"):\n",
    "    codigo_par_similar = {}\n",
    "    total_comparaciones = 0\n",
    "    pares_similares = 0\n",
    "    \n",
    "    grupos = df_filtered.groupby(['cell', 'seccion', 'numero_tabla', 'orden_obligacion', \n",
    "                                  'componente_materia', 'fase', 'tipo_obligacion', \n",
    "                                  'frecuencia', 'fuente', 'objeto'])\n",
    "    \n",
    "    total_grupos = len(list(grupos))\n",
    "    print(f\"Total de grupos a procesar: {total_grupos}\")\n",
    "    \n",
    "    # Reiniciar el iterador de grupos\n",
    "    grupos = df_filtered.groupby(['cell', 'seccion', 'numero_tabla', 'orden_obligacion', \n",
    "                                 'componente_materia', 'fase', 'tipo_obligacion', \n",
    "                                 'frecuencia', 'fuente', 'objeto'])\n",
    "    \n",
    "    grupo_contador = 0\n",
    "    guardar_cada_n_pares = 10 \n",
    "    pares_guardados_desde_ultimo = 0\n",
    "    for (cell, seccion, numero_tabla, orden_obligacion, componente_materia, fase, \n",
    "         tipo_obligacion, frecuencia, fuente, objeto), group in grupos:\n",
    "        grupo_contador += 1\n",
    "        num_frases = len(group['resumen'])\n",
    "        if num_frases <= 1:\n",
    "            print(f\"Grupo {grupo_contador}/{total_grupos} ({cell}, {seccion}, {numero_tabla}): Solo tiene 1 frase, omitiendo.\")\n",
    "            continue\n",
    "        \n",
    "        pares_frases = list(combinations(group['resumen'], 2))\n",
    "        total_comparaciones += len(pares_frases)\n",
    "        \n",
    "        print(f\"Procesando grupo {grupo_contador}/{total_grupos} ({cell}, {seccion}, {numero_tabla}): {len(pares_frases)} comparaciones\")\n",
    "        \n",
    "        for i, (frase1, frase2) in enumerate(pares_frases, 1):\n",
    "            # Mostrar progreso periódicamente\n",
    "            if i % 10 == 0 or i == len(pares_frases):\n",
    "                print(f\"  Progreso: {i}/{len(pares_frases)} comparaciones\")\n",
    "            \n",
    "            # Calcular similitud con seguimiento de uso\n",
    "            similitud, usage_info = similitud_embeddings(\n",
    "                frase1, frase2, \n",
    "                api_key, endpoint, deployment_name, api_version,\n",
    "                use_langchain=use_langchain\n",
    "            )\n",
    "            \n",
    "            # Mostrar información de uso cada cierto número de llamadas\n",
    "            if usage_info and embedding_calls % 50 == 0:\n",
    "                acumulado = usage_info['total_acumulado']\n",
    "                print(f\"\\nEstadísticas de uso de embeddings:\")\n",
    "                print(f\"  Llamadas totales: {acumulado['llamadas']}\")\n",
    "                print(f\"  Tokens totales: {acumulado['tokens']}\")\n",
    "                print(f\"  Costo total: {acumulado['costo']}\")\n",
    "                print(f\"  Comparaciones: {total_comparaciones}, Pares similares: {pares_similares}\")\n",
    "                if total_comparaciones > 0:\n",
    "                    print(f\"  Porcentaje de similitud: {(pares_similares/total_comparaciones*100):.2f}%\")\n",
    "                print(\"-\" * 40)\n",
    "            \n",
    "            # Si la similitud es mayor al umbral, registrarla\n",
    "            if similitud > umbral_similitud:\n",
    "                pares_similares += 1\n",
    "                pares_guardados_desde_ultimo += 1\n",
    "                print(f\"Similitud entre el par {i}, {cell}, {seccion}, {numero_tabla} : {similitud:.2f}%\")\n",
    "                print(f\"Frase 1: {frase1}\")\n",
    "                print(f\"Frase 2: {frase2}\")\n",
    "                if usage_info:\n",
    "                    print(f\"Tokens: {usage_info['total_tokens']}, Costo: {usage_info['costo']}\")\n",
    "                print(\"-\" * 40)\n",
    "                \n",
    "                idx_frase1 = group[group['resumen'] == frase1].index[0]\n",
    "                idx_frase2 = group[group['resumen'] == frase2].index[0]\n",
    "                codigo_par_similar[idx_frase1] = similitud\n",
    "                codigo_par_similar[idx_frase2] = similitud\n",
    "            \n",
    "                # Agregar resultados y guardar temporalmente si se cumple condición\n",
    "                df_filtered['codigo_par_similar'] = df_filtered.index.map(codigo_par_similar).fillna('N/A')\n",
    "            \n",
    "                if pares_guardados_desde_ultimo >= guardar_cada_n_pares:\n",
    "                    output_path = os.path.join(path, output_filename)\n",
    "                    df_filtered.to_excel(output_path, index=False)\n",
    "                    print(f\"[Guardado parcial] Archivo actualizado con {pares_similares} pares similares en: {output_path}\")\n",
    "                    pares_guardados_desde_ultimo = 0\n",
    "\n",
    "    print(\"\\n========== RESUMEN FINAL DE USO DE EMBEDDINGS ==========\")\n",
    "    print(f\"Total de grupos procesados: {grupo_contador}\")\n",
    "    print(f\"Total de comparaciones realizadas: {total_comparaciones}\")\n",
    "    print(f\"Total de pares similares encontrados: {pares_similares}\")\n",
    "    if total_comparaciones > 0:\n",
    "        print(f\"Porcentaje de similitud: {(pares_similares/total_comparaciones*100):.2f}%\")\n",
    "    print(f\"Total de llamadas a la API: {embedding_calls}\")\n",
    "    print(f\"Total de tokens procesados: {total_embedding_tokens}\")\n",
    "    print(f\"Costo total estimado: ${total_embedding_cost:.6f} USD\")\n",
    "    print(\"=======================================================\")\n",
    "    \n",
    "    df_filtered['codigo_par_similar'] = df_filtered.index.map(codigo_par_similar).fillna('N/A')\n",
    "    \n",
    "    # Guardar el resultado\n",
    "    output_path = os.path.join(path, output_filename)\n",
    "    df_filtered.to_excel(output_path, index=False)\n",
    "    print(f\"Archivo guardado en: {output_path}\")\n",
    "    \n",
    "    return df_filtered, {\n",
    "        'comparaciones': total_comparaciones,\n",
    "        'pares_similares': pares_similares,\n",
    "        'llamadas_api': embedding_calls,\n",
    "        'tokens_totales': total_embedding_tokens,\n",
    "        'costo_total': total_embedding_cost\n",
    "    }\n",
    "\n",
    "# Ejecutar el proceso\n",
    "df_X, estadisticas = procesar_similitudes(\n",
    "    df_filtered=df_X,\n",
    "    api_key=api_key_openai,\n",
    "    endpoint=endpoint_openai,\n",
    "    deployment_name=\"text-embedding-3-large\",\n",
    "    api_version=api_version_openai,\n",
    "    umbral_similitud=75,\n",
    "    use_langchain=False,  \n",
    "    path=\".\",\n",
    "    output_filename=os.path.join(path, \"df_obligaciones_pre_filtradas_3.xlsx\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb0cb9b-6a5a-4b1d-a1f2-642fc4f31032",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_instructions = {\n",
    "    \"obligaciones\": {\n",
    "        \"categorizar\": \"\"\"\n",
    "        Evalúa si dos obligaciones son semánticamente equivalentes (TRUE) o no (FALSE) basándote en las acciones fundamentales que exigen.\n",
    "\n",
    "        ✓ EQUIVALENTES (TRUE) cuando:\n",
    "        • Las acciones principales o resultados exigidos son fundamentalmente los mismos\n",
    "        • Una es reformulación, resumen o versión más detallada de la otra, manteniendo la esencia\n",
    "        • Las diferencias son solo de redacción, sinónimos o formato, sin cambiar sustanciamente la acción detallada\n",
    "        • La acción resultante o propósito principal coincide, aunque varíe la descripción del proceso\n",
    "\n",
    "        ✗ NO EQUIVALENTES (FALSE) cuando:\n",
    "        • Exigen acciones claramente distintas, complementarias, adicionales o faltantes entre sí\n",
    "        • Se refieren a objetos, sujetos o contextos diferentes que implican acciones distintas\n",
    "        • Difieren en alcance, magnitud, frecuencia o parámetros específicos que afectan la implementación\n",
    "        • Una obligación es significativamente más amplia o restrictiva que la otra\n",
    "\n",
    "        Responde únicamente con un objeto JSON que contenga la clave 'equivalent' con valor true o false.\n",
    "        \"\"\",\n",
    "\n",
    "        \"eg_input_1\": '''Obligación 1: \"Obtención del permiso ambiental sectorial N° 140 otorgado por la Seremi de Salud respectiva.\"\n",
    "Obligación 2: \"Obtención del permiso ambiental sectorial N° 142 otorgado por la Seremi de Salud respectiva.\"''',\n",
    "        \"eg_output_1\": '''{\"equivalent\": false}''', \n",
    "\n",
    "        \"eg_input_2\": '''Obligación 1: \"Presentar el Plan de Manejo Forestal a CONAF y obtener su aprobación.\"\n",
    "Obligación 2: \"Aprobación de Plan de Manejo Forestal por CONAF.\"''',\n",
    "        \"eg_output_2\": '''{\"equivalent\": true}''',\n",
    "\n",
    "        \"eg_input_3\": '''Obligación 1: \"Transportar los materiales en camiones con la carga cubierta.\"\n",
    "Obligación 2: \"Transporte de materiales en camiones con la carga cubierta mediante el empleo de lona.\"''',\n",
    "        \"eg_output_3\": '''{\"equivalent\": true}''', \n",
    "\n",
    "        \"eg_input_4\": '''Obligación 1: \"Realizar monitoreo trimestral de calidad del agua y presentar informes.\"\n",
    "Obligación 2: \"Monitorear semestralmente los niveles de contaminantes en agua y reportar resultados.\"''',\n",
    "        \"eg_output_4\": '''{\"equivalent\": false}''', \n",
    "\n",
    "        \"eg_input_5\": '''Obligación 1: \"Replantar especies nativas en proporción de 3:1 por cada árbol removido.\"\n",
    "Obligación 2: \"Replantar especies nativas en proporción de 2:1 por cada árbol removido.\"''',\n",
    "        \"eg_output_5\": '''{\"equivalent\": false}''', \n",
    "\n",
    "        \"eg_input_6\": '''Obligación 1: \"Realizar charlas de inducción en arqueología, resaltando importancia de la preservación del patrimonio prehispánico a trabajadores antes de excavación.\"\n",
    "Obligación 2: \"Dar una charla de inducción sobre arqueología a los trabajadores antes de iniciar la obra.\"''',\n",
    "        \"eg_output_6\": '''{\"equivalent\": true}''', \n",
    "    }\n",
    "}\n",
    "\n",
    "class ObligacionesResponse(BaseModel):\n",
    "    equivalent: bool = Field(description=\"Booleano que es TRUE cuando las obligaciones son equivalentes y FALSE en caso contrario\")\n",
    "\n",
    "response_format = ObligacionesResponse\n",
    "\n",
    "def comparar_obligaciones(client, obligacion1, obligacion2):\n",
    "    initial_messages = [\n",
    "        {\"role\": \"user\", \"content\": system_instructions[\"obligaciones\"][\"eg_input_1\"]},\n",
    "        {\"role\": \"assistant\", \"content\": system_instructions[\"obligaciones\"][\"eg_output_1\"]},\n",
    "        {\"role\": \"user\", \"content\": system_instructions[\"obligaciones\"][\"eg_input_2\"]},\n",
    "        {\"role\": \"assistant\", \"content\": system_instructions[\"obligaciones\"][\"eg_output_2\"]}\n",
    "    ]\n",
    "    \n",
    "    input_text = f'Obligación 1: \"{obligacion1}\"\\nObligación 2: \"{obligacion2}\"'\n",
    "    \n",
    "    messages = [{\"role\": \"system\", \"content\": system_instructions[\"obligaciones\"][\"categorizar\"]}]\n",
    "    messages.extend(initial_messages)\n",
    "    messages.append({\"role\": \"user\", \"content\": input_text})\n",
    "    \n",
    "    completion = client.beta.chat.completions.parse(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temperature=0,\n",
    "        response_format=response_format,\n",
    "        messages=messages,\n",
    "    )\n",
    "    \n",
    "    response_content = completion.choices[0].message.content\n",
    "    result = json.loads(response_content)\n",
    "    \n",
    "    return result[\"equivalent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8801134c-7020-4d24-9fa7-3040eb7310ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def procesar_y_deduplicar_obligaciones(df, client):\n",
    "    df_modificado = df.copy()\n",
    "    df_modificado['eliminacion_duplicados_semanticos'] = False\n",
    "    indices_a_eliminar = []\n",
    "    indices_con_duplicado_eliminado = []\n",
    "    total_grupos_procesados = 0\n",
    "    pares_equivalentes = 0\n",
    "    filas_eliminadas = 0\n",
    "    \n",
    "    count = 0 \n",
    "    for id_grupo, grupo in df.groupby(['codigo_par_similar', 'cell', 'seccion']):\n",
    "        if len(grupo) != 2:            \n",
    "            print(f\"Advertencia: El grupo identificado por {id_grupo} tiene {len(grupo)} obligaciones, se esperaban 2. Se omitirá este grupo.\")\n",
    "            continue\n",
    "\n",
    "        count = count +1 \n",
    "        total_grupos_procesados += 1\n",
    "        \n",
    "        # Extraer las dos filas\n",
    "        fila1 = grupo.iloc[0]\n",
    "        fila2 = grupo.iloc[1]\n",
    "        obligacion1_texto = f\"{fila1.get('resumen', '')} {fila1.get('justificacion', '')}\".strip()\n",
    "        obligacion2_texto = f\"{fila2.get('resumen', '')} {fila2.get('justificacion', '')}\".strip()\n",
    "        if not obligacion1_texto or not obligacion2_texto:\n",
    "            print(f\"Advertencia: Para el grupo {id_grupo}, una o ambas obligaciones resultaron vacías. Se omitirá.\")\n",
    "            print(f\"Texto Obligación 1: '{obligacion1_texto}'\")\n",
    "            print(f\"Texto Obligación 2: '{obligacion2_texto}'\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n=== COMPARACIÓN {count}/9567, PARA GRUPO ID: {id_grupo} ===\")\n",
    "        print(f\"Obligación 1 (Índice {fila1.name}): {obligacion1_texto}\")\n",
    "        print(f\"Obligación 2 (Índice {fila2.name}): {obligacion2_texto}\")\n",
    "        \n",
    "        try:\n",
    "            equivalente = comparar_obligaciones(client, obligacion1_texto, obligacion2_texto)\n",
    "            resultado_texto = 'Equivalentes' if equivalente else 'No equivalentes'\n",
    "            print(f\"Resultado: {resultado_texto}\")\n",
    "            \n",
    "            # Si son equivalentes, marcar una para eliminar y la otra para señalar como duplicado eliminado\n",
    "            if equivalente:\n",
    "                pares_equivalentes += 1\n",
    "                indice_a_eliminar = fila2.name\n",
    "                indice_a_marcar = fila1.name\n",
    "                \n",
    "                if indice_a_eliminar not in indices_a_eliminar: \n",
    "                    indices_a_eliminar.append(indice_a_eliminar)\n",
    "                if indice_a_marcar not in indices_con_duplicado_eliminado: \n",
    "                     indices_con_duplicado_eliminado.append(indice_a_marcar)\n",
    "                \n",
    "                print(f\"    → Se marcará para eliminar la fila con índice original {indice_a_eliminar}\")\n",
    "                print(f\"    → Se marcará la fila con índice original {indice_a_marcar} como TRUE en 'eliminacion_duplicados_semanticos'\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error al procesar el grupo {id_grupo}: {str(e)}\")\n",
    "    \n",
    "    final_indices_a_marcar = [idx for idx in indices_con_duplicado_eliminado if idx not in indices_a_eliminar]\n",
    "    for indice in final_indices_a_marcar:\n",
    "        if indice in df_modificado.index: \n",
    "             df_modificado.loc[indice, 'eliminacion_duplicados_semanticos'] = True\n",
    "        else:\n",
    "            print(f\"Advertencia: Índice {indice} para marcar como TRUE no encontrado en df_modificado. Pudo haber sido marcado para eliminación.\")\n",
    "\n",
    "    df_limpio = df_modificado.drop(index=list(set(indices_a_eliminar))) \n",
    "    filas_eliminadas = len(list(set(indices_a_eliminar)))\n",
    "\n",
    "    print(\"\\n=== RESUMEN DE DEDUPLICACIÓN ===\")\n",
    "    print(f\"Total de grupos de dos obligaciones procesados: {total_grupos_procesados}\")\n",
    "    print(f\"Pares equivalentes encontrados: {pares_equivalentes}\")\n",
    "    print(f\"Filas eliminadas: {filas_eliminadas}\")\n",
    "\n",
    "    filas_marcadas_true_final = df_limpio['eliminacion_duplicados_semanticos'].sum()\n",
    "    print(f\"Filas marcadas como TRUE en 'eliminacion_duplicados_semanticos' (en df limpio): {filas_marcadas_true_final}\")\n",
    "    print(f\"Filas en el DataFrame original: {len(df)}\")\n",
    "    print(f\"Filas en el DataFrame limpio: {len(df_limpio)}\")\n",
    "    \n",
    "    # Mostrar distribución de valores en la nueva columna\n",
    "    if not df_limpio.empty:\n",
    "        valor_counts = df_limpio['eliminacion_duplicados_semanticos'].value_counts()\n",
    "        print(\"\\nDistribución de valores en 'eliminacion_duplicados_semanticos' (en df limpio):\")\n",
    "        print(f\"TRUE: {valor_counts.get(True, 0)}\")\n",
    "        print(f\"FALSE: {valor_counts.get(False, 0)}\")\n",
    "    else:\n",
    "        print(\"\\nEl DataFrame limpio está vacío.\")\n",
    "        \n",
    "    return df_limpio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d433e78-8825-48e6-afc4-722ae1c03a98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    client = openai.OpenAI(\n",
    "        api_key=api_key_openai\n",
    "    )\n",
    "    df_sin_duplicados = procesar_y_deduplicar_obligaciones(df_X, client)\n",
    "df_sin_duplicados.to_excel(os.path.join(path, \"obligaciones_final_final.xlsx\"), index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b911f95-48a8-49d8-b05c-7ee320a48a04",
   "metadata": {},
   "source": [
    "### Eliminar \"No Identificados\" que tengan misma idea semántica que \"Identificados\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d51a19-b3ce-4856-8c74-d48aba7af7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sin_duplicados = pd.read_excel(os.path.join(path, \"obligaciones_final_final.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6010fc-a903-4794-81ec-f87ce50e0b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sin_duplicados.seccion.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2443ac55-bb62-4045-8659-4620250a15d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings_batch(texts, client, deployment_name, model=\"text-embedding-3-large\"):\n",
    "    global total_embedding_tokens, total_embedding_cost, embedding_calls\n",
    "    \n",
    "    valid_texts = [text for text in texts if isinstance(text, str) and text.strip()]\n",
    "    if not valid_texts:\n",
    "        return {}\n",
    "\n",
    "    # Contar tokens y calcular costo\n",
    "    tokens_count = sum(count_tokens_embeddings(text, model) for text in valid_texts)\n",
    "    cost_rate = embedding_costs.get(model, 0.00013)\n",
    "    cost = (tokens_count / 1000) * cost_rate\n",
    "    \n",
    "    # Actualizar contadores globales\n",
    "    total_embedding_tokens += tokens_count\n",
    "    total_embedding_cost += cost\n",
    "    embedding_calls += 1\n",
    "    \n",
    "    try:\n",
    "        response = client.embeddings.create(\n",
    "            input=valid_texts,\n",
    "            model=deployment_name\n",
    "        )\n",
    "        # Crear el diccionario de cache: {texto: embedding}\n",
    "        embeddings_cache = {text: np.array(data.embedding) for text, data in zip(valid_texts, response.data)}\n",
    "        return embeddings_cache\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error al obtener embeddings en lote: {e}\")\n",
    "        return {}\n",
    "\n",
    "\n",
    "def marcar_similitudes_no_identificadas(df, client, deployment_name, umbral_similitud=75, output_dir=\".\", output_filename=\"obligaciones_marcadas.xlsx\"):\n",
    "    \"\"\"\n",
    "    Busca similitudes usando un método optimizado de batching para los embeddings.\n",
    "    \"\"\"\n",
    "    print(\"Iniciando proceso optimizado de detección de similitudes...\")\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    df_copy['es_duplicado_no_identificado'] = False\n",
    "    df_copy['similar_a_fila'] = None\n",
    "    df_copy['campo_similar'] = None\n",
    "    df_copy['porcentaje_similitud'] = None\n",
    "    df_copy['contenido_similar'] = None\n",
    "    \n",
    "    pares_similares = 0\n",
    "    comparaciones_totales = 0\n",
    "    \n",
    "    for seccion, grupo_seccion in df_copy.groupby('seccion'):\n",
    "        print(f\"\\nProcesando sección: {seccion}\")\n",
    "        \n",
    "        for cell, grupo_cell in grupo_seccion.groupby('cell'):\n",
    "            print(f\"  Célula: {cell}\")\n",
    "            \n",
    "            no_identificadas = grupo_cell[grupo_cell['numero_tabla_grupo'] == 'no identificado']\n",
    "            identificadas = grupo_cell[grupo_cell['numero_tabla_grupo'] != 'no identificado']\n",
    "            \n",
    "            if len(no_identificadas) == 0 or len(identificadas) == 0:\n",
    "                continue\n",
    "\n",
    "            # 1. Recolectar todos los textos únicos\n",
    "            textos_a_procesar = set()\n",
    "            for _, row in pd.concat([no_identificadas, identificadas]).iterrows():\n",
    "                if pd.notna(row.get('justificacion')):\n",
    "                    textos_a_procesar.add(row['justificacion'])\n",
    "                if pd.notna(row.get('resumen')):\n",
    "                    textos_a_procesar.add(row['resumen'])\n",
    "\n",
    "            # 2. Obtener todos los embeddings en una sola llamada\n",
    "            if not textos_a_procesar:\n",
    "                continue\n",
    "            \n",
    "            print(f\"    Obteniendo embeddings para {len(textos_a_procesar)} textos únicos en esta célula...\")\n",
    "            embeddings_cache = get_embeddings_batch(list(textos_a_procesar), client, deployment_name)\n",
    "            \n",
    "            if not embeddings_cache:\n",
    "                print(\"    No se pudieron obtener los embeddings para esta célula.\")\n",
    "                continue\n",
    "\n",
    "            # 3. Comparar localmente usando los embeddings cacheados\n",
    "            for idx_no_id, fila_no_id in no_identificadas.iterrows():\n",
    "                mejor_similitud = 0\n",
    "                mejor_idx_id = None\n",
    "                mejor_campo = None\n",
    "\n",
    "                for idx_id, fila_id in identificadas.iterrows():\n",
    "                    comparaciones_totales += 1\n",
    "                    \n",
    "                    # Comparar justificación\n",
    "                    texto1_just = fila_no_id.get('justificacion')\n",
    "                    texto2_just = fila_id.get('justificacion')\n",
    "                    emb1 = embeddings_cache.get(texto1_just)\n",
    "                    emb2 = embeddings_cache.get(texto2_just)\n",
    "\n",
    "                    if emb1 is not None and emb2 is not None:\n",
    "                        cos_sim = dot(emb1, emb2) / (norm(emb1) * norm(emb2))\n",
    "                        cos_sim = max(min(cos_sim, 1.0), 0.0) * 100\n",
    "                        if cos_sim > mejor_similitud:\n",
    "                            mejor_similitud = cos_sim\n",
    "                            mejor_idx_id = idx_id\n",
    "                            mejor_campo = \"justificacion\"\n",
    "                    \n",
    "                    # Comparar resumen\n",
    "                    texto1_res = fila_no_id.get('resumen')\n",
    "                    texto2_res = fila_id.get('resumen')\n",
    "                    emb1 = embeddings_cache.get(texto1_res)\n",
    "                    emb2 = embeddings_cache.get(texto2_res)\n",
    "\n",
    "                    if emb1 is not None and emb2 is not None:\n",
    "                        cos_sim = dot(emb1, emb2) / (norm(emb1) * norm(emb2))\n",
    "                        cos_sim = max(min(cos_sim, 1.0), 0.0) * 100\n",
    "                        if cos_sim > mejor_similitud:\n",
    "                            mejor_similitud = cos_sim\n",
    "                            mejor_idx_id = idx_id\n",
    "                            mejor_campo = \"resumen\"\n",
    "\n",
    "                # Marcar si se encontró una similitud superior al umbral\n",
    "                if mejor_similitud > umbral_similitud and mejor_idx_id is not None:\n",
    "                    pares_similares += 1\n",
    "                    df_copy.loc[idx_no_id, 'es_duplicado_no_identificado'] = True\n",
    "                    df_copy.loc[idx_no_id, 'similar_a_fila'] = mejor_idx_id\n",
    "                    df_copy.loc[idx_no_id, 'campo_similar'] = mejor_campo\n",
    "                    df_copy.loc[idx_no_id, 'porcentaje_similitud'] = mejor_similitud\n",
    "                    df_copy.loc[idx_no_id, 'contenido_similar'] = fila_no_id.get(mejor_campo, '')\n",
    "            \n",
    "    return df_copy, {\n",
    "        'pares_similares': pares_similares,\n",
    "        'comparaciones': comparaciones_totales,\n",
    "        'filas_marcadas': df_copy['es_duplicado_no_identificado'].sum(),\n",
    "        'llamadas_api': embedding_calls,\n",
    "        'tokens_totales': total_embedding_tokens,\n",
    "        'costo_total': total_embedding_cost\n",
    "    }\n",
    "\n",
    "\n",
    "def eliminar_duplicados_marcados(df):\n",
    "    \"\"\"\n",
    "    Elimina las filas que fueron marcadas como duplicados según la columna 'es_duplicado_no_identificado'\n",
    "    \"\"\"\n",
    "    filas_marcadas = df['es_duplicado_no_identificado'].sum()\n",
    "    df_limpio = df[~df['es_duplicado_no_identificado']]\n",
    "    \n",
    "    print(f\"Se eliminaron {filas_marcadas} filas marcadas como duplicados.\")\n",
    "    print(f\"DataFrame original: {len(df)} filas\")\n",
    "    print(f\"DataFrame limpio: {len(df_limpio)} filas\")\n",
    "    \n",
    "    return df_limpio\n",
    "\n",
    "\n",
    "def procesar_similitudes_y_marcar(df, client, deployment_name, umbral_similitud=75):\n",
    "    \"\"\"\n",
    "    Función completa que integra la detección de similitud por embeddings y \n",
    "    marca las filas para su posterior eliminación.\n",
    "    \"\"\"\n",
    "    print(\"\\n=== FASE 1: DETECCIÓN Y MARCADO DE 'NO IDENTIFICADOS' SIMILARES ===\")\n",
    "    df_marcado, stats_fase1 = marcar_similitudes_no_identificadas(\n",
    "        df, \n",
    "        client,\n",
    "        deployment_name,\n",
    "        umbral_similitud=umbral_similitud\n",
    "    )\n",
    "    \n",
    "    print(\"\\n====== RESUMEN DEL PROCESO DE MARCADO ======\")\n",
    "    print(f\"Filas en el DataFrame original: {len(df)}\")\n",
    "    print(f\"Filas marcadas como duplicados: {df_marcado['es_duplicado_no_identificado'].sum()}\")\n",
    "    \n",
    "    print(\"\\nUso de embeddings:\")\n",
    "    print(f\"Total de llamadas a la API: {embedding_calls}\")\n",
    "    print(f\"Total de tokens procesados: {total_embedding_tokens}\")\n",
    "    print(f\"Costo total estimado: ${total_embedding_cost:.6f} USD\")\n",
    "    print(\"=================================================\")\n",
    "    \n",
    "\n",
    "    print(\"\\nPara eliminar las filas marcadas, puede llamar a la función 'eliminar_duplicados_marcados(df_marcado)'\")\n",
    "    \n",
    "    return df_marcado\n",
    "\n",
    "\n",
    "def count_tokens_embeddings(text, model=\"text-embedding-3-large\"):\n",
    "    \"\"\"Cuenta los tokens para el modelo de embeddings especificado.\"\"\"\n",
    "    if \"text-embedding-3\" in model:\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    else: \n",
    "        encoding = tiktoken.get_encoding(\"p50k_base\")\n",
    "    token_list = encoding.encode(text)\n",
    "    return len(token_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c77abb7-2e16-4011-8a38-4b6ec4007102",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embedding_costs = {\"text-embedding-3-large\": 0.00013}\n",
    "total_embedding_tokens = 0\n",
    "total_embedding_cost = 0.0\n",
    "embedding_calls = 0\n",
    "\n",
    "df_marcado = procesar_similitudes_y_marcar(\n",
    "    df_sin_duplicados,\n",
    "    client, \n",
    "    deployment_name=\"text-embedding-3-small\",\n",
    "    umbral_similitud=75\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c05dac7-7548-4c18-b0c9-6baa709bc321",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_limpio = eliminar_duplicados_marcados(df_marcado)\n",
    "print(f\"se eliminó un {(len(df_marcado) - len(df_limpio))*100/len(df_marcado)} % de los datos\")\n",
    "df_limpio.to_excel(os.path.join(path, \"obligaciones_final_final_2.xlsx\"), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee43146-28c1-40a4-8a3a-4d3b93733367",
   "metadata": {},
   "source": [
    "### Contingencias y Emergencias Categorizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6971e645-c337-4013-9099-1f12a07cc2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_limpio.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6e2ed9-c1d3-4686-9d5f-8949db0a5bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TipologiaPrincipalCE(str, Enum):\n",
    "    RIESGOS_OPERACIONALES = \"Riesgos Operacionales\"\n",
    "    RIESGOS_NATURALES = \"Riesgos Naturales\"  \n",
    "    RIESGOS_ANTRÓPICOS = \"Riesgos Antrópicos\"\n",
    "    NO_CLASIFICABLE = \"No Clasificable\"\n",
    "\n",
    "class SubTipologiaCE(str, Enum):\n",
    "    # Para Riesgos Operacionales\n",
    "    FALLA_DE_EQUIPOS_E_INFRAESTRUCTURA = \"Falla de Equipos e Infraestructura\"\n",
    "    DERRAME_O_FUGA_DE_PROCESO = \"Manejo de Sustancias y Residuos Peligrosos\"\n",
    "    ACCIDENTE_LABORAL_O_DE_TRANSPORTE = \"Accidente Laboral o de Transporte\"\n",
    "    INCENDIO_O_EXPLOSION_DE_ORIGEN_TECNICO = \"Incendio o Explosión de Origen Técnico\"\n",
    "    \n",
    "    # Para Riesgos Naturales\n",
    "    INCENDIOS = \"Incendios de Origen No Operacional\"\n",
    "    ESTABILIDAD_GEOTECNICA = \"Eventos Geofísicos y Geotécnicos\"\n",
    "    EVENTO_HIDROMETEOROLOGICO = \"Eventos Hidrometeorológicos\"\n",
    "    CONTAMINACION = \"Contaminación y Afectación del Aire, Agua y Suelo\"\n",
    "    AFECTACION_A_LA_BIOTA = \"Afectación a la Biota\"\n",
    "\n",
    "    # Para Riesgos Antrópicos\n",
    "    CONFLICTO_SOCIAL_O_COMUNITARIO = \"Relacionamiento Comunitario y Social\"\n",
    "    PATRIMONIO_CULTURAL = \"Patrimonio Cultural\"\n",
    "    ACTO_ILICITO_O_VANDALICO = \"Actos Ilícitos\"\n",
    "    EMERGENCIA_SANITARIA = \"Emergencias Sanitarias y Gestión de Residuos\"\n",
    "    \n",
    "    # Para No Clasificable\n",
    "    DESCRIPCION_GENERAL_O_DOCUMENTAL = \"Descripción General o Documental\"\n",
    "    OTRO = \"Otro\"\n",
    "\n",
    "class ClasificacionContingencia(BaseModel):\n",
    "    tipologia_principal: TipologiaPrincipalCE = Field(description=\"Categoría principal de la contingencia o emergencia.\")\n",
    "    sub_tipologia: SubTipologiaCE = Field(description=\"Subcategoría específica dentro de la tipología principal.\")\n",
    "\n",
    "MAPEO_TIPOLOGIAS = {\n",
    "    TipologiaPrincipalCE.RIESGOS_OPERACIONALES: [\n",
    "        SubTipologiaCE.FALLA_DE_EQUIPOS_E_INFRAESTRUCTURA,\n",
    "        SubTipologiaCE.DERRAME_O_FUGA_DE_PROCESO,\n",
    "        SubTipologiaCE.ACCIDENTE_LABORAL_O_DE_TRANSPORTE,\n",
    "        SubTipologiaCE.INCENDIO_O_EXPLOSION_DE_ORIGEN_TECNICO,\n",
    "    ],\n",
    "    TipologiaPrincipalCE.RIESGOS_NATURALES: [\n",
    "        SubTipologiaCE.INCENDIOS,\n",
    "        SubTipologiaCE.ESTABILIDAD_GEOTECNICA,\n",
    "        SubTipologiaCE.EVENTO_HIDROMETEOROLOGICO,\n",
    "        SubTipologiaCE.CONTAMINACION,\n",
    "        SubTipologiaCE.AFECTACION_A_LA_BIOTA,\n",
    "    ],\n",
    "    TipologiaPrincipalCE.RIESGOS_ANTRÓPICOS: [\n",
    "        SubTipologiaCE.CONFLICTO_SOCIAL_O_COMUNITARIO,\n",
    "        SubTipologiaCE.PATRIMONIO_CULTURAL,\n",
    "        SubTipologiaCE.ACTO_ILICITO_O_VANDALICO,\n",
    "        SubTipologiaCE.EMERGENCIA_SANITARIA,\n",
    "    ],\n",
    "    TipologiaPrincipalCE.NO_CLASIFICABLE: [\n",
    "        SubTipologiaCE.DESCRIPCION_GENERAL_O_DOCUMENTAL,\n",
    "        SubTipologiaCE.OTRO,\n",
    "    ]\n",
    "}\n",
    "\n",
    "class ClasificacionContingencia(BaseModel):\n",
    "    tipologia_principal: TipologiaPrincipalCE = Field(description=\"Categoría principal de la contingencia o emergencia.\")\n",
    "    sub_tipologia: SubTipologiaCE = Field(description=\"Subcategoría específica dentro de la tipología principal.\")\n",
    "\n",
    "    @model_validator(mode='after')\n",
    "    def validar_subtipologia_segun_tipologia(self) -> 'ClasificacionContingencia':\n",
    "        tipologia = self.tipologia_principal\n",
    "        sub_tipologia = self.sub_tipologia\n",
    "\n",
    "        if sub_tipologia not in MAPEO_TIPOLOGIAS.get(tipologia, []):\n",
    "            raise ValueError(f\"La sub-tipología '{sub_tipologia.value}' no es válida para la tipología principal '{tipologia.value}'.\")\n",
    "\n",
    "        return self\n",
    "\n",
    "try:\n",
    "    clasificacion_valida = ClasificacionContingencia(\n",
    "        tipologia_principal=\"Riesgos Naturales\",\n",
    "        sub_tipologia=\"Eventos Hidrometeorológicos\"\n",
    "    )\n",
    "    print(\"Validación exitosa:\")\n",
    "    print(clasificacion_valida.model_dump_json(indent=2))\n",
    "except ValidationError as e:\n",
    "    print(e)\n",
    "\n",
    "print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "\n",
    "try:\n",
    "    clasificacion_invalida = ClasificacionContingencia(\n",
    "        tipologia_principal=\"Riesgos Naturales\",\n",
    "        sub_tipologia=\"Falla de Equipos e Infraestructura\"  \n",
    "    )\n",
    "except ValidationError as e:\n",
    "    print(\"Validación fallida como se esperaba:\")\n",
    "    print(e)\n",
    "\n",
    "system_instructions = \"\"\"\n",
    "                        Eres un experto en gestión de riesgos y planes de contingencia para proyectos de gran escala (minería, energía, infraestructura). Tu tarea es clasificar descripciones de contingencias o emergencias o acciones según una tipología específica y estructurada.\n",
    "                        \n",
    "                        **CATEGORÍAS Y DEFINICIONES:**\n",
    "                        \n",
    "                        **1. Riesgos Operacionales:** Fallas, errores o accidentes originados DENTRO de la operación del proyecto. La causa es técnica o humana no intencional.\n",
    "                           - **Falla de Equipos e Infraestructura:** Una máquina se rompe, una tubería se corroe, un sistema eléctrico falla.\n",
    "                           - **Manejo de Sustancias y Residuos Peligrosos:** Un derrame o fuga causado por una falla en un proceso, una bomba, estanque, relave u otro.\n",
    "                           - **Accidente Laboral o de Transporte:** Una persona se accidenta operando maquinaria; un camión del proyecto choca por error del conductor.\n",
    "                           - **Incendio o Explosión de Origen Técnico:** El fuego o explosión, comienza por un cortocircuito, sobrecalentamiento, tronadura, falla de un equipo, acumulación de gases u otro.\n",
    "                        \n",
    "                        **2. Riesgos Naturales:** Eventos externos gatillados por el entorno físico o cuyo impacto principal es ambiental sin una causa operacional.\n",
    "                           - **Incendios de Origen No Operacional:**  Fuego en vegetación circundante que afecta o es afectado por el proyecto.\n",
    "                           - **Eventos Geofísicos y Geotécnicos:** Sismos, erupciones, aluviones, o la inestabilidad de un botadero, talud o tranque.\n",
    "                           - **Eventos Hidrometeorológicos:** Lluvias torrenciales, inundaciones, nevazones, sequías, tormentas eléctricas.\n",
    "                           - **Contaminación y Afectación del Aire, Agua y Suelo:**  Emisiones; degradación de suelos;  alteración de cauces, afloramientos y contaminación en general.\n",
    "                           - **Afectación a la Biota:** El texto describe principalmente un daño a animales o vegetación (ej. atropello de fauna).\n",
    "                        \n",
    "                        **3. Riesgos Antrópicos:** Acciones o conflictos asociados a personas o grupos humanos.\n",
    "                           - **Relacionamiento Comunitario y Social:** Protestas, bloqueos, huelgas, conflictos con comunidades.\n",
    "                           - **Patrimonio Cultural:** Hallazgo o afectación de sitios arqueológicos o paleontológicos.\n",
    "                           - **Actos Ilícitos:** Robo, hurto, sabotaje, vandalismo, ataques intencionados.\n",
    "                           - **Emergencias Sanitarias y Gestión de Residuos:** Proliferación de enfermedades, problemas sanitarios por mala gestión de residuos, entre otros.\n",
    "                        \n",
    "                        **4. No Clasificable:**\n",
    "                           - **Descripción General o Documental:** El texto no describe un evento de riesgo, sino un plan, un protocolo, un procedimiento, o es excesivamente vago (\"Todo el proyecto\", \"Control y seguimiento\").\n",
    "                        \n",
    "                        **INSTRUCCIONES CLAVE:**\n",
    "                        1.  Lee atentamente la descripción de la contingencia.\n",
    "                        2.  Clasifica en la **tipología principal** la que sea MÁS representativa. \n",
    "                        3.  Selecciona la **subtipología** que MEJOR se ajuste DENTRO de esa categoría principal.\n",
    "                        4.  Entiende las categorías en un sentido amplio (es posible que no cuadre exactamente, sé flexible). \n",
    "                        5.  **USA \"NO CLASIFICABLE\" SÓLO COMO ÚLTIMO RECURSO:** Aplícalo solo para frases vagas, u otras acciones de control que sean extremadamente difíciles de clasificar.\n",
    "                        5.  Responde ÚNICAMENTE en el formato JSON solicitado. No agregues explicaciones ni texto adicional fuera del JSON.\n",
    "                        \"\"\"\n",
    "\n",
    "initial_messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Acciones de contingencia para el área de espesado de relaves y relaveducto. Derrame de pulpa de relaves y líquidos en área de espesado. - Derrames de relaves desde relaveducto. - Derrames de agua de procesos en el trazado de cañerías de recirculación de agua.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"\"\"\n",
    "        {\n",
    "            \"tipologia_principal\": \"Riesgos Operacionales\",\n",
    "            \"sub_tipologia\": \"Manejo de Sustancias y Residuos Peligrosos\"\n",
    "        }\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Acciones ante contingencias en caminos de acceso durante la operación. Contingencias relacionadas con caminos de acceso en donde se puedan producir contingencias tal como deslizamientos tierras y rocas.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"\"\"\n",
    "        {\n",
    "            \"tipologia_principal\": \"Riesgos Naturales\",\n",
    "            \"sub_tipologia\": \"Eventos Geofísicos y Geotécnicos\"\n",
    "        }\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Acciones de emergencia para oficinas y talleres. Posibilidad que se generen incendios y explosiones por una mala ejecución de protocolos en cuanto al manejo de materiales inflamables y/o combustibles, así como también la ocurrencia de una contingencia eléctrica.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"\"\"\n",
    "        {\n",
    "            \"tipologia_principal\": \"Riesgos Operacionales\",\n",
    "            \"sub_tipologia\": \"Incendio o Explosión de Origen Técnico\"\n",
    "        }\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Acciones de contingencia para piscinas y plataformas en fase de construcción. Riesgo de alteración accidental de sitios arqueológicos\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"\"\"\n",
    "        {\n",
    "            \"tipologia_principal\": \"Riesgos Antrópicos\",\n",
    "            \"sub_tipologia\": \"Patrimonio Cultural\"\n",
    "        }\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Acciones de contingencia ante procesos erosivos y riesgos a la seguridad de los trabajadores\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"\"\"\n",
    "        {\n",
    "            \"tipologia_principal\": \"Riesgos Operacionales\",\n",
    "            \"sub_tipologia\": \"Accidente Laboral o de Transporte\"\n",
    "        }\n",
    "        \"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"\"\"Acciones de contingencia para el Sistema de Transporte de Relaves\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": \"\"\"\n",
    "        {\n",
    "            \"tipologia_principal\": \"Riesgos Operacionales\",\n",
    "            \"sub_tipologia\": \"Falla de Equipos e Infraestructura\"\n",
    "        }\n",
    "        \"\"\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bcbe4f-1e3e-4489-854f-ff4b3762fb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clasificar_iniciativa(client, texto_a_clasificar):\n",
    "    \"\"\"\n",
    "    Clasifica un texto dado utilizando un modelo de IA con instrucciones de sistema\n",
    "    y ejemplos de few-shot para guiar la respuesta.\n",
    "    \"\"\"\n",
    "    messages = copy.deepcopy(initial_messages)\n",
    "    messages.insert(0, {\"role\": \"system\", \"content\": system_instructions})\n",
    "    messages.append({\"role\": \"user\", \"content\": texto_a_clasificar})\n",
    "    \n",
    "    try:\n",
    "\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            temperature=0,\n",
    "            response_format=ClasificacionContingencia,\n",
    "            messages=messages,\n",
    "            timeout=30.0,  \n",
    "        )\n",
    "        \n",
    "        \n",
    "        resultado = completion.choices[0].message.parsed\n",
    "        return resultado.tipologia_principal.value, resultado.sub_tipologia.value\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error al clasificar iniciativa: {e}\")\n",
    "        return \"Error en API\", \"Error en API\"\n",
    "\n",
    "def clasificar_iniciativa(client, texto_a_clasificar, max_retries=2):\n",
    "    \"\"\"\n",
    "    Clasifica un texto, reintentando con retroalimentación si ocurre un error de validación.\n",
    "    \"\"\"\n",
    "    messages = copy.deepcopy(initial_messages)\n",
    "    messages.insert(0, {\"role\": \"system\", \"content\": system_instructions})\n",
    "    messages.append({\"role\": \"user\", \"content\": texto_a_clasificar})\n",
    "\n",
    "    # Bucle para controlar los reintentos\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            completion = client.beta.chat.completions.parse(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                temperature=0,\n",
    "                response_format=ClasificacionContingencia,\n",
    "                messages=messages,\n",
    "                timeout=30.0,\n",
    "            )\n",
    "            \n",
    "            resultado = completion.choices[0].message.parsed\n",
    "            return resultado.tipologia_principal.value, resultado.sub_tipologia.value\n",
    "\n",
    "        except ValidationError as e:\n",
    "            print(f\"🚨 Error de Validación en el intento {attempt + 1}:\")\n",
    "            print(e)\n",
    "\n",
    "            if attempt == max_retries - 1:\n",
    "                print(\"❌ Se alcanzó el número máximo de reintentos. La clasificación falló.\")\n",
    "                break \n",
    "\n",
    "            \n",
    "            feedback_message = (\n",
    "                \"Tu respuesta anterior no fue válida. \"\n",
    "                f\"Error: {e}. \"\n",
    "                \"Por favor, corrige tu respuesta para que la 'sub_tipologia' sea una opción válida \"\n",
    "                \"para la 'tipologia_principal' que seleccionaste. Revisa las reglas y genera una nueva respuesta JSON válida.\"\n",
    "            )\n",
    "            \n",
    "            messages.append({\"role\": \"user\", \"content\": feedback_message})\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"--- Error General de API ---\")\n",
    "            print(f\"Ocurrió un error inesperado: {e}\")\n",
    "            return \"Error en API\", \"La solicitud falló\"\n",
    "\n",
    "    return \"Clasificación Fallida\", \"El modelo no pudo generar una respuesta válida tras varios intentos.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27cb728-cd78-42a0-83e4-7c0ec0c59c94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    try:\n",
    "        df[\"Tipologia_CE\"] = \"\"\n",
    "        df[\"Subtipologia_CE\"] = \"\"\n",
    "\n",
    "        filas_a_clasificar = df[\n",
    "            (df['seccion'] == 'contingencias_emergencias') & \n",
    "            (df['resumen'].str.len() > 5)\n",
    "        ]\n",
    "        \n",
    "        if filas_a_clasificar.empty:\n",
    "            print(\"No se encontraron filas que cumplan con las condiciones. Finalizando.\")\n",
    "            return\n",
    "\n",
    "        print(f\"DataFrame total: {len(df)} filas.\")\n",
    "        print(f\"Se clasificarán {len(filas_a_clasificar)} filas que cumplen con los criterios. 🤖\")\n",
    "        \n",
    "        ruta_salida = os.path.join(path, \"obligaciones_clasificadas.xlsx\")\n",
    "        for i, (index, row) in enumerate(tqdm(filas_a_clasificar.iterrows(), total=len(filas_a_clasificar), desc=\"Clasificando\")):\n",
    "            try:\n",
    "                texto_a_clasificar = f\"{row['resumen']} {row['justificacion']}\"\n",
    "                \n",
    "                tipologia, subtipologia = clasificar_iniciativa(\n",
    "                    client,\n",
    "                    texto_a_clasificar\n",
    "                )\n",
    "                \n",
    "                df.at[index, \"Tipologia_CE\"] = tipologia\n",
    "                df.at[index, \"Subtipologia_CE\"] = subtipologia\n",
    "                if (i + 1) % 3000 == 0:\n",
    "                    print(f\"\\nGuardando progreso en la fila {i+1}...\")\n",
    "                    df.to_excel(ruta_salida, index=False)\n",
    "                \n",
    "                time.sleep(0.4)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error procesando fila con índice {index}: {e}\")\n",
    "                df.at[index, \"Tipologia_CE\"] = \"Error en Proceso\"\n",
    "                df.at[index, \"Subtipologia_CE\"] = \"Error en Proceso\"\n",
    "\n",
    "        print(\"\\n✅ Proceso de clasificación completado.\")\n",
    "        \n",
    "        # --- GUARDADO FINAL ---\n",
    "        print(f\"Guardando resultados finales en: {ruta_salida}\")\n",
    "        df.to_excel(ruta_salida, index=False)\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ Error: No se pudo encontrar el archivo de entrada.\")\n",
    "    except KeyError:\n",
    "        print(\"❌ Error: Asegúrate de que las columnas 'seccion' y 'resumen' existan.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Ocurrió un error general: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e4bf9e-3496-49c1-b660-040562e9facf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(os.path.join(path, \"obligaciones_clasificadas.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c61d08-3fc5-4940-885b-4cb8222121b5",
   "metadata": {},
   "source": [
    "### Obligaciones Expandidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925badfb-4746-4c99-9f85-1422c974a902",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.environ['USERPROFILE'], \"RUTA\")\n",
    "df0 = pd.read_excel(os.path.join(path, \"obligaciones_clasificadas.xlsx\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65d5329-cefa-44fd-a459-bec16c10b6f6",
   "metadata": {},
   "source": [
    "#### Eliminar más duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bcbd51-a954-4eb7-8295-4e7dade481ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procesado = df0.copy()\n",
    "\n",
    "# --- CÁLCULO ESTADÍSTICO ---\n",
    "total_inicial = len(df_procesado)\n",
    "pas_inicial = len(df_procesado[df_procesado['seccion'] == 'pas'])\n",
    "contingencias_inicial = len(df_procesado[df_procesado['seccion'] == 'contingencias_emergencias'])\n",
    "\n",
    "# --- INICIO: PROCESAMIENTO DEL DATAFRAME ---\n",
    "df_a_mantener = df_procesado[~df_procesado['seccion'].isin(['pas', 'contingencias_emergencias'])].copy()\n",
    "df_a_procesar = df_procesado[df_procesado['seccion'].isin(['pas', 'contingencias_emergencias'])].copy()\n",
    "df_a_procesar['largo_contenido'] = df_a_procesar['resumen'].str.len().fillna(0) + \\\n",
    "                                   df_a_procesar['justificacion'].str.len().fillna(0)\n",
    "\n",
    "df_a_procesar = df_a_procesar.sort_values('largo_contenido', ascending=False)\n",
    "columnas_clave = ['cell', 'seccion', 'numero_tabla']\n",
    "df_sin_duplicados = df_a_procesar.drop_duplicates(subset=columnas_clave, keep='first')\n",
    "df_sin_duplicados = df_sin_duplicados.drop(columns=['largo_contenido'])\n",
    "\n",
    "\n",
    "df_final = pd.concat([df_sin_duplicados, df_a_mantener], ignore_index=True)\n",
    "# --- FIN: PROCESAMIENTO DEL DATAFRAME ---\n",
    "\n",
    "\n",
    "# --- INICIO: IMPRESIÓN DE RESULTADOS ---\n",
    "total_final = len(df_final)\n",
    "pas_final = len(df_final[df_final['seccion'] == 'pas'])\n",
    "contingencias_final = len(df_final[df_final['seccion'] == 'contingencias_emergencias'])\n",
    "\n",
    "filas_eliminadas = total_inicial - total_final\n",
    "pas_eliminadas = pas_inicial - pas_final\n",
    "contingencias_eliminadas = contingencias_inicial - contingencias_final\n",
    "\n",
    "\n",
    "porcentaje_total_eliminado = (filas_eliminadas / total_inicial) * 100 if total_inicial > 0 else 0\n",
    "porcentaje_pas_eliminado = (pas_eliminadas / pas_inicial) * 100 if pas_inicial > 0 else 0\n",
    "porcentaje_contingencias_eliminado = (contingencias_eliminadas / contingencias_inicial) * 100 if contingencias_inicial > 0 else 0\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "print(\"📊 --- Estadísticas de Eliminación --- 📊\")\n",
    "print(f\"Filas eliminadas: {filas_eliminadas} de {total_inicial} ({porcentaje_total_eliminado:.2f}% del total).\")\n",
    "print(f\"Filas de 'pas' eliminadas: {pas_eliminadas} de {pas_inicial} ({porcentaje_pas_eliminado:.2f}% de las filas 'pas').\")\n",
    "print(f\"Filas de 'contingencias_emergencias' eliminadas: {contingencias_eliminadas} de {contingencias_inicial} ({porcentaje_contingencias_eliminado:.2f}% de las filas 'contingencias').\")\n",
    "print(\"\\n\" + \"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c98447-cecd-4b6d-9db2-22ed301f8a13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307c6626-caa4-44fb-a6c6-d143d3a030e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Condición para seleccionar las filas\n",
    "df = df_final.copy()\n",
    "condicion = (df['seccion'] == 'compromisos_voluntarios') & (df['fuente'] == \"['decisión de autoridad']\")\n",
    "df.loc[condicion, 'fuente'] = \"['Compromiso ambiental voluntario']\"\n",
    "condicion = (df['fuente'] == \"[]\") | (df['numero_fuente'] == \"[]\") \n",
    "df.loc[condicion, 'fuente'] = \"['decisión de autoridad']\"\n",
    "df.loc[condicion, 'numero_fuente'] = \"['']\"\n",
    "\n",
    "def clean_numero_fuente(numero_fuente_str):\n",
    "    try:\n",
    "        lista = ast.literal_eval(numero_fuente_str)\n",
    "        if len(lista) == 1 and isinstance(lista[0], str):\n",
    "            if ',' in lista[0]:\n",
    "                parts = [part.strip() for part in lista[0].split(',')]\n",
    "                return str(parts)\n",
    "            elif 'y' in lista[0]:\n",
    "                parts = [part.strip() for part in lista[0].split('y')]\n",
    "                return str(parts)\n",
    "        return str(lista)\n",
    "    except (ValueError, SyntaxError):\n",
    "        return numero_fuente_str\n",
    "\n",
    "df['numero_fuente'] = df['numero_fuente'].apply(clean_numero_fuente)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe11d94-74ab-4a04-82b5-6c65ae06f953",
   "metadata": {},
   "source": [
    "#### Expandir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8cfcd4-5c5b-47de-ad04-acadeb4c5c22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def expandir_fuentes_modificado(df):\n",
    "    \"\"\"\n",
    "    Expande las filas del DataFrame basado en las columnas 'fuente' y 'numero_fuente',\n",
    "    identifica las filas no procesadas y cuenta las obligaciones.\n",
    "    \n",
    "    Devuelve:\n",
    "        - pd.DataFrame: El nuevo DataFrame expandido (df2).\n",
    "        - list: Una lista con los índices de las filas del df original que no se incluyeron.\n",
    "        - dict: Un diccionario con el recuento de obligaciones en el df original y en el nuevo.\n",
    "    \"\"\"\n",
    "    filas_expandidas = []\n",
    "    filas_no_incluidas_indices = []\n",
    "    \n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            fuentes = ast.literal_eval(row[\"fuente\"])\n",
    "            numeros_fuentes = ast.literal_eval(row[\"numero_fuente\"])\n",
    "            \n",
    "            if not isinstance(fuentes, list) or not isinstance(numeros_fuentes, list):\n",
    "                raise ValueError(\"El contenido no es una lista\")\n",
    "\n",
    "        except (ValueError, SyntaxError):\n",
    "            filas_no_incluidas_indices.append(idx)\n",
    "            continue\n",
    "        \n",
    "        if not fuentes or not numeros_fuentes:\n",
    "            filas_no_incluidas_indices.append(idx)\n",
    "            continue\n",
    "        \n",
    "        obligacion_id = str(uuid.uuid4())\n",
    "        \n",
    "        if len(fuentes) > 1:\n",
    "            for fuente, numero in zip(fuentes, numeros_fuentes):\n",
    "                nueva_fila = row.copy()\n",
    "                nueva_fila[\"obligacion_id\"] = obligacion_id\n",
    "                nueva_fila[\"fuente\"] = str(fuente).replace(\"['\", \"\").replace(\"']\", \"\")\n",
    "                nueva_fila[\"numero_fuente\"] = str(numero).replace(\"['\", \"\").replace(\"']\", \"\")\n",
    "                filas_expandidas.append(nueva_fila)\n",
    "        else:\n",
    "            row[\"obligacion_id\"] = obligacion_id\n",
    "            row[\"fuente\"] = str(fuentes[0]).replace(\"['\", \"\").replace(\"']\", \"\")\n",
    "            row[\"numero_fuente\"] = str(numeros_fuentes[0]).replace(\"['\", \"\").replace(\"']\", \"\")\n",
    "            filas_expandidas.append(row)\n",
    "    \n",
    "    df_expandido = pd.DataFrame(filas_expandidas).reset_index(drop=True)\n",
    "    \n",
    "    recuentos = {\n",
    "        \"Obligaciones en df original\": len(df),\n",
    "        \"Obligaciones procesadas en df2\": df_expandido[\"obligacion_id\"].nunique() if not df_expandido.empty else 0\n",
    "    }\n",
    "    \n",
    "    return df_expandido, filas_no_incluidas_indices, recuentos\n",
    "\n",
    "df2, filas_omitidas, conteos = expandir_fuentes_modificado(df)\n",
    "\n",
    "print(\"📊 RECUENTO DE OBLIGACIONES:\")\n",
    "for nombre, valor in conteos.items():\n",
    "    print(f\"- {nombre}: {valor}\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "if filas_omitidas:\n",
    "    print(f\"⚠️ Se omitieron {len(filas_omitidas)} fila(s) del DataFrame original debido a errores de formato o datos vacíos.\")\n",
    "    print(\"Filas no incluidas (índices: {}):\".format(', '.join(map(str, filas_omitidas))))\n",
    "    print(df.loc[filas_omitidas])\n",
    "else:\n",
    "    print(\"👍 Todas las filas del DataFrame original fueron procesadas exitosamente.\")\n",
    "\n",
    "print(\"-\" * 30)\n",
    "print(\"🔍 VISTA PREVIA DEL NUEVO DATAFRAME (df2):\")\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac4a0a1-2c01-41ff-bbcc-6fd0b095e578",
   "metadata": {},
   "source": [
    "#### Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095dd753-5861-457a-8a1d-0c791ae51c07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def limpiar_y_estandarizar_fuentes(row):\n",
    "    fuente = row['fuente']\n",
    "    numero_fuente = str(row['numero_fuente'])\n",
    "\n",
    "    reglas = [\n",
    "        (r'\\b(NCh\\s*Elec)\\b', 'norma chilena electrica'),\n",
    "        (r'\\b(Norma\\s*Chilena|NCH|NCh)\\b', 'norma chilena'),\n",
    "        (r'\\b(DFL)\\b', 'decreto con fuerza de ley'),\n",
    "        (r'\\b(DS)\\b', 'decreto supremo'),\n",
    "        (r'\\b(Ley)\\b', 'ley'),\n",
    "        (r'\\b(ordenanza general|ordenanza municipal|ordenanza|ORD)\\b', 'ordenanza'),\n",
    "        (r'\\b(Constitución\\s*Política\\s*de\\s*la\\s*República|CPR|constitucion)\\b', 'constitucion politica'),\n",
    "        (r'\\b(Resolución\\s*Exenta|Resolución|R.E.|RES EX|RES N°|RES Nº|RES|RE)\\b', 'resolucion'),\n",
    "        (r'\\b(Ordenanza\\s*General\\s*de\\s*Urbanismo\\s*y\\s*Construcciones|OGUC)\\b', 'oguc'),\n",
    "        (r'\\b(Plan\\s*Regulador)\\b', 'plan regulador'),\n",
    "        (r'\\b(ordenanza\\s*municipal)\\b', 'ordenanza municipal'),\n",
    "        (r'\\b(RGR)\\b', 'rgr'),\n",
    "        (r'\\b(NSEG)\\b', 'nseg'),\n",
    "        (r'\\b(NSEC)\\b', 'nsec')\n",
    "    ]\n",
    "\n",
    "    for patron, nueva_fuente in reglas:\n",
    "        if re.search(patron, numero_fuente, re.IGNORECASE):\n",
    "            print(rf\"Encontrado patrón {patron} en {numero_fuente}\")\n",
    "            fuente = nueva_fuente\n",
    "            numero_fuente = re.sub(patron, '', numero_fuente, flags=re.IGNORECASE).strip()\n",
    "            break\n",
    "            \n",
    "    patron_limpieza = r'\\b(Norma\\s*Oficial|Norma|No)\\b|\\b(N\\s*°|N\\s*º|N°|Nº)'\n",
    "    numero_fuente = re.sub(patron_limpieza, '', numero_fuente, flags=re.IGNORECASE)\n",
    "    numero_fuente = re.sub(r'^N(\\d)', r'\\1', numero_fuente.strip())\n",
    "    numero_fuente = numero_fuente.replace(':', '/')\n",
    "    numero_fuente = numero_fuente.replace('.', '')\n",
    "    numero_fuente = numero_fuente.replace(' Of ', '/')\n",
    "    numero_fuente = numero_fuente.replace(' of ', '/')\n",
    "    numero_fuente = numero_fuente.replace('Of', '/')\n",
    "    numero_fuente = numero_fuente.replace('of', '/')\n",
    "    numero_fuente = ' '.join(numero_fuente.split())\n",
    "\n",
    "    return pd.Series([fuente, numero_fuente])\n",
    "\n",
    "df2[['fuente', 'numero_fuente']] = df2.apply(limpiar_y_estandarizar_fuentes, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02081583-73bf-496b-89b3-91009ea546c5",
   "metadata": {},
   "source": [
    "#### Normalizar Año Fuente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9f2e93-bc59-432a-968a-ea2a93dcfe67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def normalizar_ano_fuente_corregido(valor):\n",
    "    \"\"\"\n",
    "    Normaliza y valida un valor de fuente.\n",
    "    - Convierte formatos como 'número/aa' o números enteros largos a 'código/aaaa'.\n",
    "    - Valida que el año resultante esté entre 1900 y 2025.\n",
    "    - Si el año es inválido, imprime una advertencia y devuelve el valor original.\n",
    "    \"\"\"\n",
    "    if valor is None:\n",
    "        return None\n",
    "    valor_str = str(valor).strip()\n",
    "    \n",
    "    codigo_final = None\n",
    "    ano_final_str = None\n",
    "\n",
    "    m = re.match(r'^(\\d+)/(\\d{2})$', valor_str)\n",
    "    if m:\n",
    "        codigo_final, ano_corto = m.groups()\n",
    "        ano_corto_int = int(ano_corto)\n",
    "        if 0 <= ano_corto_int <= 25:\n",
    "            ano_final_str = f\"20{ano_corto.zfill(2)}\"\n",
    "        else:\n",
    "            ano_final_str = f\"19{ano_corto.zfill(2)}\"\n",
    "\n",
    "    elif valor_str.isdigit():\n",
    "        longitud = len(valor_str)\n",
    "        # Ejemplo: 12342023 -> 1234/2023\n",
    "        if longitud == 8:\n",
    "            codigo_final = valor_str[:4]\n",
    "            ano_final_str = valor_str[4:]\n",
    "        # Ejemplo: 1232023 -> 123/2023\n",
    "        elif longitud == 7:\n",
    "            codigo_final = valor_str[:3]\n",
    "            ano_final_str = valor_str[3:]\n",
    "\n",
    "    if ano_final_str:\n",
    "        ano_int = int(ano_final_str)\n",
    "        if 1900 <= ano_int <= 2025:\n",
    "            return f\"{codigo_final}/{ano_final_str}\"\n",
    "        else:\n",
    "            print(f\"⚠️ Advertencia: El año '{ano_int}' extraído de '{valor_str}' está fuera del rango (1900-2025).\")\n",
    "            return valor_str\n",
    "            \n",
    "    return valor_str\n",
    "\n",
    "df2[\"numero_fuente\"] = df2[\"numero_fuente\"].apply(normalizar_ano_fuente_corregido)\n",
    "print(\"Normalización corregida aplicada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a5e628-4065-49c0-ad55-180b30084e25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df2['ano_num'] = pd.to_numeric(df2['numero_fuente'], errors='coerce')\n",
    "df2['group_size'] = df2.groupby('obligacion_id')['obligacion_id'].transform('size')\n",
    "filas_a_procesar_mask = (\n",
    "    (df2['ano_num'] >= 1900) &\n",
    "    (df2['ano_num'] <= 2025) &\n",
    "    (df2['group_size'] > 1) &\n",
    "    (df2['ano_num'].notna())\n",
    ")\n",
    "mapa_obligacion_ano = df2[filas_a_procesar_mask].set_index('obligacion_id')['ano_num'].astype(int).astype(str).to_dict()\n",
    "\n",
    "for obligacion_id, ano_a_agregar in mapa_obligacion_ano.items():\n",
    "    filas_a_modificar_mask = (\n",
    "        (df2['obligacion_id'] == obligacion_id) &\n",
    "        (df2['numero_fuente'] != ano_a_agregar) &\n",
    "        (~df2['numero_fuente'].str.contains('/'))\n",
    "    )\n",
    "    df2.loc[filas_a_modificar_mask, 'numero_fuente'] = df2.loc[filas_a_modificar_mask, 'numero_fuente'] + '/' + ano_a_agregar\n",
    "\n",
    "indices_a_eliminar = df2[filas_a_procesar_mask].index\n",
    "df2 = df2.drop(indices_a_eliminar)\n",
    "\n",
    "\n",
    "df2 = df2.drop(columns=['ano_num', 'group_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9535d722-ab50-41ff-8301-d8a6b316b5e2",
   "metadata": {},
   "source": [
    "#### Definir Variables de Fuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d98d262-3ea1-4613-8ee4-3d4ed1e4ec88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numero_fuente_counts = df2[\"numero_fuente\"].value_counts()\n",
    "reemplazos = {}\n",
    "\n",
    "for fuente in numero_fuente_counts.index:\n",
    "    fuente_str = str(fuente)\n",
    "    if fuente_str and not re.search(r'/\\d+$', fuente_str) and fuente != 1:\n",
    "        posibles_coincidencias = [\n",
    "            f for f in numero_fuente_counts.index \n",
    "            if re.match(rf'^{re.escape(fuente_str)}/\\d+$', str(f))\n",
    "        ]\n",
    "        if posibles_coincidencias:\n",
    "            mejor_coincidencia = max(posibles_coincidencias, key=lambda x: numero_fuente_counts[x])\n",
    "            reemplazos[fuente_str] = mejor_coincidencia\n",
    "            print(fuente_str, \"a\", mejor_coincidencia)\n",
    "df2[\"numero_fuente\"] = df2[\"numero_fuente\"].replace(reemplazos)\n",
    "df2['numero_fuente_completo'] = df2['numero_fuente']\n",
    "df2['año_fuente'] = None\n",
    "\n",
    "def extraer_ano(valor):\n",
    "    if isinstance(valor, str):\n",
    "        if '/' in valor:\n",
    "            parts = valor.split('/')\n",
    "            return parts[1]\n",
    "        if '-' in valor:\n",
    "            parts = valor.split('-')\n",
    "            if len(parts) == 2 and parts[1].isdigit():\n",
    "                return parts[1]\n",
    "    return None\n",
    "\n",
    "def extraer_numero(valor):\n",
    "    if isinstance(valor, str):\n",
    "        if '/' in valor:\n",
    "            return valor.split('/')[0]\n",
    "        if '-' in valor:\n",
    "            return valor.split('-')[0]\n",
    "    return valor\n",
    "\n",
    "\n",
    "df2['año_fuente'] = df2['numero_fuente_completo'].apply(extraer_ano)\n",
    "df2['numero_fuente'] = df2['numero_fuente_completo'].apply(extraer_numero)\n",
    "df2['numero_fuente'] = df2['numero_fuente'].str.replace('.', '', regex=False)\n",
    "\n",
    "# Convertir año_fuente a número entero cuando sea posible\n",
    "def convertir_a_entero(valor):\n",
    "    if valor is not None:\n",
    "        try:\n",
    "            return int(valor)\n",
    "        except (ValueError, TypeError):\n",
    "            return valor\n",
    "    return valor\n",
    "\n",
    "df2['año_fuente'] = df2['año_fuente'].apply(convertir_a_entero)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b28ce056-57a5-4202-98fd-08999918beed",
   "metadata": {},
   "source": [
    "#### Limpieza Normas Identificadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f580d359-e03c-41fb-b4a8-73bc39bddd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_normas_raw = \"\"\"\n",
    "decreto supremo 47/1992\n",
    "decreto supremo 100/2005\n",
    "decreto supremo 109/2017\n",
    "decreto supremo 112/2013\n",
    "decreto con fuerza de ley 1122/1981\n",
    "resolucion 1139/2013\n",
    "decreto supremo 114/2002\n",
    "decreto supremo 115/2004\n",
    "decreto supremo 1150/1980\n",
    "decreto supremo 1164/1974\n",
    "decreto supremo 12/2021\n",
    "ley 1215/1978\n",
    "decreto supremo 125/2019\n",
    "decreto supremo 1261/1957\n",
    "decreto supremo 13/2011\n",
    "decreto supremo 132/2002\n",
    "decreto supremo 133/2005\n",
    "decreto supremo 138/2005\n",
    "decreto supremo 144/1961\n",
    "decreto supremo 146/1997\n",
    "decreto supremo 148/2003\n",
    "decreto supremo 149/2006\n",
    "decreto supremo 15/2013\n",
    "decreto supremo 151/2006\n",
    "resolucion 1518/2013\n",
    "decreto supremo 157/2007\n",
    "decreto supremo 158/1980\n",
    "ley 15840/1964\n",
    "decreto supremo 160/2008\n",
    "resolucion 499/2006\n",
    "decreto supremo 1665/2002\n",
    "ley 16744/1968\n",
    "decreto supremo 172/1988\n",
    "ley 17288/1970\n",
    "ley 17798/1972\n",
    "decreto supremo 18/2001\n",
    "ley 18248/1983\n",
    "ley 18290/1984\n",
    "ley 18378/1984\n",
    "ley 18695/1988\n",
    "ley 18755/1989\n",
    "ley 18834/1989\n",
    "ley 18892/1989\n",
    "decreto con fuerza de ley 19/1984\n",
    "ley 19253/1993\n",
    "decreto supremo 193/1998\n",
    "ley 19300/1994\n",
    "decreto supremo 194/1973\n",
    "ley 19473/1996\n",
    "ley 19880/2003\n",
    "decreto supremo 20/2013\n",
    "decreto supremo 200/1993\n",
    "ley 20001/2005\n",
    "ley 20096/2006\n",
    "ley 20283/2008\n",
    "ley 20380/2009\n",
    "ley 20389/2009\n",
    "ley 20417/2010\n",
    "ley 20443/2010\n",
    "ley 20551/2011\n",
    "ley 20724/2014\n",
    "ley 20879/2015\n",
    "ley 20920/2016\n",
    "ley 20936/2017\n",
    "decreto supremo 211/1991\n",
    "ley 21455/2022\n",
    "resolucion 223/2015\n",
    "resolucion 232/2002\n",
    "decreto supremo 236/1926\n",
    "decreto supremo 244/2005\n",
    "decreto supremo 248/2007\n",
    "decreto ley 2565/1979\n",
    "decreto supremo 259/1980\n",
    "decreto supremo 276/1980\n",
    "decreto supremo 279/1983\n",
    "decreto supremo 29/2011\n",
    "decreto supremo 291/2007\n",
    "decreto supremo 294/1984\n",
    "decreto supremo 298/1994\n",
    "decreto supremo 30/2012\n",
    "decreto supremo 300/1994\n",
    "decreto supremo 327/1997\n",
    "decreto ley 3557/1980\n",
    "resolucion 359/2005\n",
    "decreto supremo 37/2019\n",
    "decreto supremo 38/2011\n",
    "decreto supremo 40/2012\n",
    "decreto supremo 400/1977\n",
    "decreto supremo 405/1983\n",
    "decreto supremo 41/2012\n",
    "decreto supremo 4188/1955\n",
    "decreto supremo 42/2011\n",
    "decreto supremo 430/1991\n",
    "decreto supremo 4363/1931\n",
    "decreto supremo 44/2017\n",
    "decreto supremo 446/2006\n",
    "decreto con fuerza de ley 458/1975\n",
    "decreto supremo 46/2002\n",
    "decreto supremo 4601/1929\n",
    "decreto supremo 461/1995\n",
    "decreto supremo 48/2016\n",
    "decreto supremo 484/1990\n",
    "decreto supremo 5/1998\n",
    "decreto supremo 531/1967\n",
    "decreto supremo 54/1994\n",
    "decreto supremo 55/1994\n",
    "ley 58/2004\n",
    "decreto supremo 59/1998\n",
    "decreto supremo 594/1999\n",
    "decreto supremo 6/2009\n",
    "resolucion 610/1982\n",
    "decreto con fuerza de ley 4/2006\n",
    "decreto supremo 65/2015\n",
    "decreto supremo 655/1940\n",
    "decreto supremo 66/2009\n",
    "decreto supremo 68/2021\n",
    "decreto supremo 7/2009\n",
    "decreto ley 701/1974\n",
    "decreto supremo 72/1985\n",
    "decreto con fuerza de ley 725/1967\n",
    "decreto supremo 735/1969\n",
    "decreto supremo 75/1987\n",
    "decreto supremo 78/2009\n",
    "decreto supremo 80/2004\n",
    "decreto supremo 82/2010\n",
    "decreto supremo 83/2007\n",
    "decreto ley 830/1974\n",
    "decreto con fuerza de ley 850/1997\n",
    "decreto supremo 867/1978\n",
    "decreto supremo 878/2011\n",
    "decreto supremo 88/2020\n",
    "decreto supremo 90/2000\n",
    "decreto supremo 93/2008\n",
    "decreto supremo 938/2011\n",
    "decreto supremo 95/2001\n",
    "\"\"\"\n",
    "\n",
    "data_corregida = []\n",
    "for line in io.StringIO(lista_normas_raw).readlines():\n",
    "    if not line.strip():\n",
    "        continue\n",
    "    fuente, numero_año = line.strip().rsplit(' ', 1)\n",
    "    numero, año = numero_año.split('/')\n",
    "    data_corregida.append({\n",
    "        'numero_fuente_ajustado': str(numero),\n",
    "        'fuente': str(fuente),\n",
    "        'año_fuente': str(año)\n",
    "    })\n",
    "\n",
    "df_mapeo = pd.DataFrame(data_corregida)\n",
    "df_mapeo_indexed = df_mapeo.set_index('numero_fuente_ajustado')\n",
    "\n",
    "df2['numero_fuente'] = df2['numero_fuente'].astype(str)\n",
    "df2['año_fuente'] = df2['año_fuente'].astype(str)\n",
    "df2['fuente'] = df2['fuente'].astype(str)\n",
    "df2['numero_fuente_ajustado'] = df2['numero_fuente']\n",
    "\n",
    "\n",
    "for index, regla in df_mapeo.iterrows():\n",
    "    numero_correcto = regla['numero_fuente_ajustado']\n",
    "    fuente_correcta = regla['fuente']\n",
    "    ano_correcto = int(regla['año_fuente'])\n",
    "    mascara_filas_a_evaluar = (df2['numero_fuente_ajustado'] == numero_correcto)\n",
    "\n",
    "    if not mascara_filas_a_evaluar.any():\n",
    "        continue\n",
    "\n",
    "    def aplicar_reglas_de_reemplazo(ano_actual_str):\n",
    "        try:\n",
    "            ano_actual_num = int(float(ano_actual_str))\n",
    "        except (ValueError, TypeError):\n",
    "            return str(ano_correcto)\n",
    "\n",
    "        if not (1900 <= ano_actual_num <= 2025):\n",
    "            return str(ano_correcto)\n",
    "\n",
    "        if abs(ano_actual_num - ano_correcto) == 1:\n",
    "            return str(ano_correcto)\n",
    "\n",
    "        return str(ano_actual_num)\n",
    "\n",
    "    df2.loc[mascara_filas_a_evaluar, 'año_fuente'] = df2.loc[mascara_filas_a_evaluar, 'año_fuente'].apply(aplicar_reglas_de_reemplazo)\n",
    "    df2.loc[mascara_filas_a_evaluar, 'fuente'] = fuente_correcta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee3c8aa-de3e-400b-8497-51fe12957ab4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lista_normas_maestra = \"\"\"\n",
    "fuente;numero_fuente_ajustado;año_fuente\n",
    "decreto con fuerza de ley;1;1990\n",
    "resolucion;1;1995\n",
    "decreto con fuerza de ley;1;2002\n",
    "decreto con fuerza de ley;1;2009\n",
    "decreto supremo;1;2013\n",
    "decreto con fuerza de ley;1;1982\n",
    "decreto supremo;4;1994\n",
    "decreto con fuerza de ley;4;20018\n",
    "decreto supremo;4;2009\n",
    "decreto supremo;8;1993\n",
    "decreto supremo;8;2019\n",
    "decreto supremo;31;2012\n",
    "decreto supremo;31;2016\n",
    "decreto supremo;43;2012\n",
    "decreto supremo;43;2015\n",
    "\"\"\"\n",
    "\n",
    "df_master = pd.read_csv(io.StringIO(lista_normas_maestra), sep=';')\n",
    "print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
    "df_to_correct = df2.copy()\n",
    "df_original = df_to_correct.copy()\n",
    "\n",
    "def clean_dataframe(df):\n",
    "    df['fuente'] = df['fuente'].astype(str)\n",
    "    df['numero_fuente_ajustado'] = df['numero_fuente_ajustado'].astype(str)\n",
    "    df['año_fuente'] = df['año_fuente'].astype(str).str.extract(r'(\\d{4})', expand=False)\n",
    "    df['numero_fuente_ajustado'] = pd.to_numeric(df['numero_fuente_ajustado'], errors='coerce')\n",
    "    df['año_fuente'] = pd.to_numeric(df['año_fuente'], errors='coerce')\n",
    "    df['numero_fuente_ajustado'] = df['numero_fuente_ajustado'].astype('Int64')\n",
    "    df['año_fuente'] = df['año_fuente'].astype('Int64')\n",
    "    return df\n",
    "\n",
    "df_master = clean_dataframe(df_master)\n",
    "df_to_correct = clean_dataframe(df_to_correct)\n",
    "\n",
    "mapa_fuente_correcta = df_master.set_index(['numero_fuente_ajustado', 'año_fuente'])['fuente'].to_dict()\n",
    "df_to_correct['key'] = list(zip(df_to_correct['numero_fuente_ajustado'], df_to_correct['año_fuente']))\n",
    "df_to_correct['fuente_correcta'] = df_to_correct['key'].map(mapa_fuente_correcta)\n",
    "df_to_correct['fuente'] = np.where(\n",
    "    (df_to_correct['fuente_correcta'].notna()) & (df_to_correct['fuente_correcta'] != df_to_correct['fuente']),\n",
    "    df_to_correct['fuente_correcta'], \n",
    "    df_to_correct['fuente']          \n",
    ")\n",
    "df_to_correct = df_to_correct.drop(columns=['key', 'fuente_correcta'])\n",
    "\n",
    "mapa_año_typo = {}\n",
    "for _, row in df_master.iterrows():\n",
    "    numero = row['numero_fuente_ajustado']\n",
    "    fuente = row['fuente']\n",
    "    año_correcto = row['año_fuente']\n",
    "    mapa_año_typo[(numero, fuente, año_correcto - 1)] = año_correcto\n",
    "    mapa_año_typo[(numero, fuente, año_correcto + 1)] = año_correcto\n",
    "\n",
    "df_to_correct['key_typo'] = list(zip(df_to_correct['numero_fuente_ajustado'], df_to_correct['fuente'], df_to_correct['año_fuente']))\n",
    "df_to_correct['año_corregido'] = df_to_correct['key_typo'].map(mapa_año_typo)\n",
    "df_to_correct['año_fuente'] = np.where(\n",
    "    df_to_correct['año_corregido'].notna(),\n",
    "    df_to_correct['año_corregido'],\n",
    "    df_to_correct['año_fuente']     \n",
    ")\n",
    "\n",
    "df_to_correct['año_fuente'] = df_to_correct['año_fuente'].astype('Int64')\n",
    "df_to_correct = df_to_correct.drop(columns=['key_typo', 'año_corregido'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eef7bb1-a92f-4243-a0e6-2a44ac213333",
   "metadata": {},
   "source": [
    "### Eliminar los vacíos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01929ea-029e-4c08-b214-aee0d93b183d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procesado = df_to_correct.copy()\n",
    "mask_fuente = df_procesado['fuente'] == 'permisos ambientales sectoriales'\n",
    "numeros_en_pas = pd.to_numeric(df_procesado.loc[mask_fuente, 'numero_fuente_ajustado'], errors='coerce')\n",
    "mask_condiciones = (numeros_en_pas < 111) | (numeros_en_pas > 161) | (numeros_en_pas.isna())\n",
    "\n",
    "indices_a_reemplazar = numeros_en_pas[mask_condiciones].index\n",
    "df_procesado['numero_fuente_ajustado'] = df_procesado['numero_fuente_ajustado'].astype(object)\n",
    "df_procesado.loc[indices_a_reemplazar, 'numero_fuente_ajustado'] = \"No identificado\"\n",
    "df_procesado = df_procesado.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ccb731-aeca-4d41-8c95-526451bc6947",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procesado.to_excel(os.path.join(path, \"df_procesasdo.xlsx\"))\n",
    "pas = pd.read_excel(os.path.join(path, \"pas.xlsx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c74fe-071a-424d-9fef-5ec016aa17fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procesado = pd.read_excel(r\"RUTA\\df_procesasdo.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98135b37-83e7-4196-a5d5-a0425ce8eba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text, deployment_name):\n",
    "    \"\"\"Obtiene el embedding para un texto dado.\"\"\"\n",
    "    response = client.embeddings.create(input=[text], model=deployment_name)\n",
    "    return np.array(response.data[0].embedding)\n",
    "\n",
    "def cosine_similarity(emb1, emb2):\n",
    "    \"\"\"Calcula la similitud coseno entre dos embeddings.\"\"\"\n",
    "    return dot(emb1, emb2) / (norm(emb1) * norm(emb2)) if (norm(emb1) * norm(emb2)) != 0 else 0\n",
    "\n",
    "print(\"Generando embeddings para los nombres de los PAS...\")\n",
    "pas_embeddings_data = []\n",
    "try:\n",
    "    if 'pas' in globals() and 'nombre' in pas.columns and 'numero_fuente' in pas.columns:\n",
    "        for index, row in pas.iterrows():\n",
    "            if pd.notna(row['nombre']):\n",
    "                embedding = get_embedding(row['nombre'], \"text-embedding-3-large\")\n",
    "                pas_embeddings_data.append((row['numero_fuente'], embedding))\n",
    "        print(f\"Embeddings de {len(pas_embeddings_data)} PAS generados exitosamente.\")\n",
    "    else:\n",
    "        print(\"Error: El DataFrame 'pas' o las columnas 'nombre'/'numero_fuente' no están definidas.\")\n",
    "        pas_embeddings_data = []\n",
    "except Exception as e:\n",
    "    print(f\"Error al generar embeddings para los PAS: {e}\")\n",
    "    pas_embeddings_data = []\n",
    "    \n",
    "mask_no_identificado = df_procesado['numero_fuente_ajustado'] == 'No identificado'\n",
    "indices_a_procesar = df_procesado[mask_no_identificado].index\n",
    "print(f\"Se procesarán {len(indices_a_procesar)} filas con 'No identificado'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5769bf-af2a-46e2-9b78-d756590c6db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pas_embeddings_data:\n",
    "    umbral_similitud = 0.60\n",
    "    print(f\"\\nIniciando proceso de corrección con umbral de similitud > {umbral_similitud}...\")\n",
    "\n",
    "    for i, index in enumerate(indices_a_procesar):\n",
    "        row = df_procesado.loc[index]\n",
    "        \n",
    "        resumen = str(row.get('resumen', ''))\n",
    "        justificacion = str(row.get('justificacion', ''))\n",
    "        texto_a_comparar = f\"{resumen}. {justificacion}\".strip()\n",
    "\n",
    "        if not texto_a_comparar or texto_a_comparar == '.':\n",
    "            print(f\"Fila {i+1}/{len(indices_a_procesar)} (Índice: {index}): Omitida por falta de texto.\")\n",
    "            continue\n",
    "            \n",
    "        print(\"-\" * 50)\n",
    "        print(f\"Procesando fila {i+1}/{len(indices_a_procesar)} (Índice: {index})\")\n",
    "\n",
    "        try:\n",
    "            embedding_fila = get_embedding(texto_a_comparar, \"text-embedding-3-large\")\n",
    "            similitudes_candidatos = []\n",
    "            for pas_numero, pas_embedding in pas_embeddings_data:\n",
    "                similitud = cosine_similarity(embedding_fila, pas_embedding)\n",
    "                similitudes_candidatos.append({'pas_numero': pas_numero, 'similitud': similitud})\n",
    "            \n",
    "\n",
    "            similitudes_candidatos.sort(key=lambda x: x['similitud'], reverse=True)\n",
    "            current_cell_id = row['cell']\n",
    "            pas_usados_en_cell = set(\n",
    "                df_procesado[\n",
    "                    (df_procesado['cell'] == current_cell_id) &\n",
    "                    (df_procesado.index != index) \n",
    "                ]['numero_fuente_ajustado']\n",
    "            )\n",
    "            \n",
    "            print(f\"Documento (cell): {current_cell_id}. PAS ya asignados en este doc: {pas_usados_en_cell if pas_usados_en_cell else 'Ninguno'}\")\n",
    "\n",
    "            asignacion_exitosa = False\n",
    "            for candidato in similitudes_candidatos:\n",
    "                pas_candidato_numero = candidato['pas_numero']\n",
    "                similitud_candidato = candidato['similitud']\n",
    "\n",
    "                if similitud_candidato > umbral_similitud:\n",
    "                    if pas_candidato_numero not in pas_usados_en_cell:\n",
    "                        df_procesado.loc[index, 'numero_fuente_ajustado'] = pas_candidato_numero\n",
    "                        print(f\"✅ Fila {index}: Corregido a PAS {pas_candidato_numero} (Similitud: {similitud_candidato:.4f}).\")\n",
    "                        asignacion_exitosa = True\n",
    "                        break \n",
    "                    else:\n",
    "                        print(f\"⚠️ Candidato PAS {pas_candidato_numero} (Similitud: {similitud_candidato:.4f}) descartado. Ya está asignado en este documento.\")\n",
    "                else:\n",
    "                    print(f\"⛔ No se encontraron más candidatos por sobre el umbral de {umbral_similitud}. Máxima similitud fue {similitudes_candidatos[0]['similitud']:.4f}.\")\n",
    "                    break \n",
    "\n",
    "            if not asignacion_exitosa:\n",
    "                print(f\"❌ Fila {index}: No se pudo asignar un PAS. Ningún candidato cumplió los criterios de similitud y unicidad.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando la fila {index}: {e}\")\n",
    "\n",
    "print(\"\\nProceso de corrección finalizado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fbf244-f650-47fe-a786-aac0e47cd585",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procesado['numero_fuente_ajustado'] = df_procesado['numero_fuente_ajustado'].astype(object)\n",
    "condicion_relleno = (\n",
    "    (~df_procesado['fuente'].isin(['Compromiso ambiental voluntario', 'decisión de autoridad'])) &\n",
    "    (df_procesado['numero_fuente_ajustado'].isnull() | (df_procesado['numero_fuente_ajustado'] == 0))\n",
    ")\n",
    "df_procesado.loc[condicion_relleno, 'numero_fuente_ajustado'] = df_procesado['numero_fuente_completo']\n",
    "es_fuente_invalida_check = (\n",
    "    df_procesado['numero_fuente_ajustado'].isnull() |\n",
    "    df_procesado['numero_fuente_ajustado'].isin([0, '0', ''])\n",
    ")\n",
    "\n",
    "condicion_invalida = (\n",
    "    (~df_procesado['fuente'].isin(['Compromiso ambiental voluntario', 'decisión de autoridad'])) &\n",
    "    (es_fuente_invalida_check)\n",
    ")\n",
    "\n",
    "\n",
    "df_procesado['conteo_fuentes_validas'] = (~condicion_invalida).astype(int)\n",
    "df_procesado['conteo_fuentes_validas'] = df_procesado.groupby('obligacion_id')['conteo_fuentes_validas'].transform('sum')\n",
    "\n",
    "condicion_modificar = condicion_invalida & (df_procesado['conteo_fuentes_validas'] == 0)\n",
    "df_procesado.loc[condicion_modificar, 'fuente'] = 'decisión de autoridad'\n",
    "\n",
    "condicion_eliminar = condicion_invalida & (df_procesado['conteo_fuentes_validas'] > 0)\n",
    "df_procesado = df_procesado[~condicion_eliminar].copy()\n",
    "\n",
    "df_procesado.drop(columns=['conteo_fuentes_validas'], inplace=True)\n",
    "print(f\"Registros: {len(df0)}\")\n",
    "print(f\"Registros: {len(df)}\")\n",
    "print(f\"Registros originales: {len(df2)}, Obligaciones originales: {df2.obligacion_id.nunique()}\")\n",
    "print(f\"Registros originales: {len(df_to_correct)}, Obligaciones originales: {df_to_correct.obligacion_id.nunique()}\")\n",
    "print(f\"Registros procesados: {len(df_procesado)}, Obligaciones procesadas: {df_procesado.obligacion_id.nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0aebaa-55aa-4eff-992f-49e4291ed00e",
   "metadata": {},
   "source": [
    "### Correcciones Manuales Básicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad935b2-0567-44c0-aa83-bd31efacb992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_reglas_unificadas(df, reglas):\n",
    "    \"\"\"\n",
    "    Aplica una serie de reglas para estandarizar las columnas de un DataFrame.\n",
    "\n",
    "    Cada regla especifica un patrón de búsqueda y los nuevos valores para las columnas\n",
    "    'fuente', 'numero_fuente_ajustado' y 'año_fuente'.\n",
    "    \"\"\"\n",
    "    df_actualizado = df.copy()\n",
    "    for regla in reglas:\n",
    "        patron = regla['patron']\n",
    "        fuente_nueva = regla['fuente_nueva']\n",
    "        numero_nuevo = regla['numero_nuevo']\n",
    "        año_nuevo = regla['año_nuevo']\n",
    "        condicion = df_actualizado['numero_fuente_ajustado'].str.contains(\n",
    "            patron, \n",
    "            case=False, \n",
    "            na=False, \n",
    "            regex=True\n",
    "        )\n",
    "        df_actualizado.loc[condicion, 'fuente'] = fuente_nueva\n",
    "        df_actualizado.loc[condicion, 'numero_fuente_ajustado'] = int(numero_nuevo)\n",
    "        \n",
    "        if año_nuevo:\n",
    "            df_actualizado.loc[condicion, 'año_fuente'] = int(año_nuevo)\n",
    "            \n",
    "    return df_actualizado\n",
    "\n",
    "reglas_normativas = [\n",
    "    {'patron': r'c[oó]digo\\s+sanitario', 'fuente_nueva': 'código', 'numero_nuevo': '725', 'año_nuevo': '1967'},\n",
    "    {'patron': r'c[oó]digo\\s+de\\s+aguas', 'fuente_nueva': 'código', 'numero_nuevo': '1122', 'año_nuevo': '1981'},\n",
    "    {'patron': r'general\\s+de\\s+pesca\\s+y\\s+acuicultura|lgpa', 'fuente_nueva': 'ley', 'numero_nuevo': '18892', 'año_nuevo': '1989'},\n",
    "    {'patron': r'ley\\s+general\\s+de\\s+urbanismo\\s+y\\s+construcci[oó]n(es)?|lguc', 'fuente_nueva': 'decreto con fuerza de ley', 'numero_nuevo': '458', 'año_nuevo': '1976'},\n",
    "    {'patron': r'general\\s+de\\s+servicios\\s+el[eé]ctricos', 'fuente_nueva': 'decreto con fuerza de ley', 'numero_nuevo': '4', 'año_nuevo': '2006'},\n",
    "    {'patron': r'caza', 'fuente_nueva': 'ley', 'numero_nuevo': '19473', 'año_nuevo': '1996'},\n",
    "    {'patron': r'ley\\s+de\\s+bosques', 'fuente_nueva': 'decreto supremo', 'numero_nuevo': '4363', 'año_nuevo': '1931'},\n",
    "    {'patron': r'monumentos\\s+nacionales', 'fuente_nueva': 'ley', 'numero_nuevo': '17288', 'año_nuevo': '1970'},\n",
    "    {'patron': r'protecci[oó]n\\s+agr[ií]cola', 'fuente_nueva': 'decreto ley', 'numero_nuevo': '3557', 'año_nuevo': '1980'},\n",
    "    {'patron': r'caminos', 'fuente_nueva': 'decreto con fuerza de ley', 'numero_nuevo': '850', 'año_nuevo': '1997'},\n",
    "    {'patron': r'tr[aá]nsito', 'fuente_nueva': 'ley', 'numero_nuevo': '18290', 'año_nuevo': '1984'},\n",
    "    {'patron': r'responsabilidad\\s+extendida\\s+del\\s+productor|REP', 'fuente_nueva': 'ley', 'numero_nuevo': '20920', 'año_nuevo': '2016'}\n",
    "]\n",
    "reglas_administrativo = [\n",
    "    {'patron': r'ley\\s+de\\s+bases\\s+de\\s+los\\s+procedimientos\\s+administrativos|ley\\s+19880', 'fuente_nueva': 'ley', 'numero_nuevo': '19880', 'año_nuevo': '2003'},\n",
    "    {'patron': r'ley\\s+org[aá]nica\\s+constitucional\\s+de\\s+municipalidades|ley\\s+18695', 'fuente_nueva': 'ley', 'numero_nuevo': '18695', 'año_nuevo': '1988'},\n",
    "    {'patron': r'estatuto\\s+administrativo', 'fuente_nueva': 'ley', 'numero_nuevo': '18834', 'año_nuevo': '1989'},\n",
    "]\n",
    "reglas_laboral = [\n",
    "    {'patron': r'ley\\s+de\\s+accidentes\\s+del\\s+trabajo\\s+y\\s+enfermedades\\s+profesionales|ley\\s+16744', 'fuente_nueva': 'ley', 'numero_nuevo': '16744', 'año_nuevo': '1968'},\n",
    "    {'patron': r'ley\\s+de\\s+isapres', 'fuente_nueva': 'decreto con fuerza de ley', 'numero_nuevo': '1', 'año_nuevo': '2005'},\n",
    "]\n",
    "reglas_ambiente = [\n",
    "    {'patron': r'ley\\s+sobre\\s+bases\\s+generales\\s+del\\s+medio\\s+ambiente|lbgma|ley\\s+19300', 'fuente_nueva': 'ley', 'numero_nuevo': '19300', 'año_nuevo': '1994'},\n",
    "    {'patron': r'sistema\\s+de\\s+evaluaci[oó]n\\s+de\\s+impacto\\s+ambiental|seia', 'fuente_nueva': 'ley', 'numero_nuevo': '19300', 'año_nuevo': '1994'},\n",
    "    {'patron': r'ley\\s+org[aá]nica\\s+de\\s+la\\s+superintendencia\\s+del\\s+medio\\s+ambiente|losma|ley\\s+20417', 'fuente_nueva': 'ley', 'numero_nuevo': '20417', 'año_nuevo': '2010'},\n",
    "]\n",
    "reglas_codigos = [\n",
    "    {'patron': r'c[oó]digo\\s+del\\s+trabajo', 'fuente_nueva': 'decreto con fuerza de ley', 'numero_nuevo': '1', 'año_nuevo': '2002'},\n",
    "    {'patron': r'c[oó]digo\\s+tributario', 'fuente_nueva': 'decreto ley', 'numero_nuevo': '830', 'año_nuevo': '1974'},\n",
    "    {'patron': r'c[oó]digo\\s+de\\s+miner[ií]a|c[oó]digo\\+minero', 'fuente_nueva': 'ley', 'numero_nuevo': '18248', 'año_nuevo': '1983'},\n",
    "]\n",
    "\n",
    "todas_las_reglas = (\n",
    "    reglas_normativas + \n",
    "    reglas_administrativo + \n",
    "    reglas_laboral + \n",
    "    reglas_ambiente + \n",
    "    reglas_codigos\n",
    ")\n",
    "\n",
    "df_procesado = aplicar_reglas_unificadas(df_procesado, todas_las_reglas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168858a9-0f25-4446-a915-68012492984f",
   "metadata": {},
   "outputs": [],
   "source": [
    "condicion = (df_procesado['numero_fuente_ajustado'] == 9725)  | (df_procesado['numero_fuente_ajustado'] == 72567)  | (df_procesado['numero_fuente_ajustado'] == 725) \n",
    "df_procesado.loc[condicion, 'año_fuente'] = 1967\n",
    "df_procesado.loc[condicion, 'fuente'] = \"decreto con fuerza de ley\"\n",
    "df_procesado.loc[condicion, 'numero_fuente_ajustado'] = 725\n",
    "\n",
    "condicion = (df_procesado['numero_fuente_ajustado'] == 9594) | (df_procesado['numero_fuente_ajustado'] == 59499) | (df_procesado['numero_fuente_ajustado'] == 549) \n",
    "df_procesado.loc[condicion, 'año_fuente'] = 1999\n",
    "df_procesado.loc[condicion, 'fuente'] = \"decreto supremo\"\n",
    "df_procesado.loc[condicion, 'numero_fuente_ajustado'] = 594\n",
    "\n",
    "condicion = (df_procesado['numero_fuente_ajustado'] == 9144 ) | (df_procesado['numero_fuente_ajustado'] == 14461) | (df_procesado['numero_fuente_ajustado'] == 144) \n",
    "df_procesado.loc[condicion, 'año_fuente'] = 1961\n",
    "df_procesado.loc[condicion, 'fuente'] = \"decreto supremo\"\n",
    "df_procesado.loc[condicion, 'numero_fuente_ajustado'] = 144\n",
    "\n",
    "condicion = (df_procesado['numero_fuente_ajustado'] == 9484 ) | (df_procesado['numero_fuente_ajustado'] == 48490) | (df_procesado['numero_fuente_ajustado'] == 484) \n",
    "df_procesado.loc[condicion, 'año_fuente'] = 1990\n",
    "df_procesado.loc[condicion, 'fuente'] = \"decreto supremo\"\n",
    "df_procesado.loc[condicion, 'numero_fuente_ajustado'] = 484\n",
    "\n",
    "condicion = (df_procesado['numero_fuente_ajustado'] == 1 ) & (df_procesado['año_fuente'] == 2007 )  \n",
    "df_procesado.loc[condicion, 'año_fuente'] = 2009\n",
    "df_procesado.loc[condicion, 'fuente'] = \"decreto con fuerza de ley\"\n",
    "\n",
    "condicion = (df_procesado['numero_fuente_ajustado'] == 1 ) & (df_procesado['año_fuente'] == 1989 ) \n",
    "df_procesado.loc[condicion, 'año_fuente'] = 1990\n",
    "df_procesado.loc[condicion, 'fuente'] = \"decreto con fuerza de ley\"\n",
    "\n",
    "condicion = (df_procesado['numero_fuente_ajustado'] == 1518 ) & (df_procesado['año_fuente'] == 2013 ) \n",
    "df_procesado.loc[condicion, 'fuente'] = \"resolucion\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9462bf8-5fc9-4307-b959-cb55eb142247",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procesado['Tipologia_CE'] = df_procesado['Tipologia_CE'].str.replace('Clasificación Fallida', 'No Clasificado')\n",
    "df_procesado['Tipologia_CE'] = df_procesado['Tipologia_CE'].str.replace('No Clasificable', 'No Clasificado')\n",
    "df_procesado['Tipologia_CE'].fillna('No Clasificado', inplace=True)\n",
    "\n",
    "df_procesado['Subtipologia_CE'] = df_procesado['Subtipologia_CE'].str.replace('El modelo no pudo generar una respuesta válida tras varios intentos.', 'No Clasificado')\n",
    "df_procesado['Subtipologia_CE'] = df_procesado['Subtipologia_CE'].str.replace('Descripción General o Documental', 'No Clasificado')\n",
    "df_procesado['Subtipologia_CE'].fillna('No Clasificado', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4fa64e-3d72-4d61-8d2e-cddec107038a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el DataFrame actualizado\n",
    "df_procesado.to_excel(os.path.join(path, \"obligaciones_combinadas_expandidas_ajustadas.xlsx\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15177e32-567a-43e5-9aff-2a7c22869676",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procesado.loc[df_procesado['seccion'] == 'pas', 'fuente'] = 'permisos ambientales sectoriales'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537b03fb-d477-4784-84cf-b2bdef97fac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_procesado.to_excel(r\"RUTA\\obligaciones_combinadas_expandidas_ajustadas.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
